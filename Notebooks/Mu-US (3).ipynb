{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2908,"status":"ok","timestamp":1642760442496,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04592796515262324641"},"user_tz":0},"id":"vHRmq_hoMZ52","outputId":"44e2cd20-ec24-451a-9e2b-fdf4e5dc6cfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow 1.x selected.\n","1.15.2\n"]}],"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27092,"status":"ok","timestamp":1642760471313,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04592796515262324641"},"user_tz":0},"id":"ESs5wUs5Iz0A","outputId":"ca8ffcb4-2c61-4776-db0c-bdd5e2bfc7b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1544,"status":"ok","timestamp":1640171834878,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04592796515262324641"},"user_tz":0},"id":"5q6SpAXx2KCF","outputId":"7575281a-83f5-4891-ae1a-4178cc95c87e"},"outputs":[{"name":"stdout","output_type":"stream","text":[" BF-C2DL-HSC.zip\t   CheckNotebook_Mu-Ba-US.ipynb  'Mu-Ba-US = ctc682'\n","'CALT-US = ctc636'\t   CheckNotebook_MU-Ra-US.ipynb  'MU-Ra-US = ctc681 SW'\n","'CALT-US = ctc636.ipynb'   CheckNotebook_PURDUS.ipynb\t 'PURD-US = ctc288'\n"]}],"source":["import os\n","os.chdir('/content/drive/MyDrive/Estibaliz Gomez de Mariscal/CELL TRACKING CHALLENGE (CTC)/CTC trainable solutions/Data Estibaliz')\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":877,"status":"ok","timestamp":1642760472182,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04592796515262324641"},"user_tz":0},"id":"r5If6tFFmOTR","outputId":"8000b26c-7aef-4bf4-d857-cd17349b3807"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'DMNet_Rina'...\n","remote: Enumerating objects: 295, done.\u001b[K\n","remote: Counting objects: 100% (295/295), done.\u001b[K\n","remote: Compressing objects: 100% (134/134), done.\u001b[K\n","remote: Total 295 (delta 157), reused 295 (delta 157), pack-reused 0\u001b[K\n","Receiving objects: 100% (295/295), 815.66 KiB | 11.49 MiB/s, done.\n","Resolving deltas: 100% (157/157), done.\n"]}],"source":["!git clone https://github.com/CIVA-Lab/DMNet_Rina.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30694,"status":"ok","timestamp":1642760502874,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04592796515262324641"},"user_tz":0},"id":"21iQvSp9oGAI","outputId":"71a8a2e0-e404-4977-d00d-31c9ef0d5564"},"outputs":[{"name":"stdout","output_type":"stream","text":["â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n","ðŸ“¦ Installing...\n","ðŸ“Œ Adjusting configuration...\n","ðŸ©¹ Patching environment...\n","â² Done in 0:00:27\n","ðŸ” Restarting kernel...\n"]}],"source":["!pip install -q condacolab\n","import condacolab\n","condacolab.install()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247784,"status":"ok","timestamp":1642760750651,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04592796515262324641"},"user_tz":0},"id":"536UemVeoW5t","outputId":"16af6047-081f-4509-a03b-642e45b6f50b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n","Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n","\n","\n","==> WARNING: A newer version of conda exists. <==\n","  current version: 4.9.2\n","  latest version: 4.11.0\n","\n","Please update conda by running\n","\n","    $ conda update -n base conda\n","\n","\n","\n","Downloading and Extracting Packages\n","libidn2-2.3.1        | 85 KB     | : 100% 1.0/1 [00:00<00:00,  6.55it/s]\n","ncurses-6.2          | 817 KB    | : 100% 1.0/1 [00:00<00:00,  3.98it/s]\n","libtasn1-4.16.0      | 58 KB     | : 100% 1.0/1 [00:00<00:00, 10.51it/s]\n","libdap4-3.19.1       | 15.6 MB   | : 100% 1.0/1 [00:02<00:00,  2.63s/it]               \n","libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00, 25.65it/s]\n","pcre-8.44            | 261 KB    | : 100% 1.0/1 [00:00<00:00, 13.68it/s]\n","poppler-0.65.0       | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  4.93it/s]\n","libgfortran4-7.5.0   | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  4.13it/s]\n","libcurl-7.68.0       | 564 KB    | : 100% 1.0/1 [00:00<00:00,  8.69it/s]\n","gnutls-3.6.15        | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  8.51it/s]\n","libpng-1.6.37        | 278 KB    | : 100% 1.0/1 [00:00<00:00, 10.25it/s]\n","tk-8.6.10            | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  2.08it/s]\n","ninja-1.10.2         | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  7.76it/s]\n","nettle-3.7.3         | 809 KB    | : 100% 1.0/1 [00:00<00:00,  8.66it/s]\n","mkl_random-1.2.1     | 305 KB    | : 100% 1.0/1 [00:00<00:00, 10.33it/s]\n","gdal-2.3.3           | 1005 KB   | : 100% 1.0/1 [00:00<00:00,  8.63it/s]\n","torchaudio-0.8.1     | 4.4 MB    | : 100% 1.0/1 [00:01<00:00,  1.80s/it]\n","pixman-0.40.0        | 627 KB    | : 100% 1.0/1 [00:00<00:00,  8.55it/s]\n","hdf5-1.10.4          | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.25it/s]\n","proj4-5.2.0          | 7.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.33it/s]\n","blas-1.0             | 1 KB      | : 100% 1.0/1 [00:00<00:00, 27.85it/s]\n","openjpeg-2.4.0       | 444 KB    | : 100% 1.0/1 [00:00<00:00, 10.73it/s]\n","numpy-1.21.1         | 6.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.17s/it]\n","fontconfig-2.13.0    | 227 KB    | : 100% 1.0/1 [00:00<00:00,  9.19it/s]\n","ffmpeg-4.3           | 9.9 MB    | : 100% 1.0/1 [00:01<00:00,  1.79s/it] \n","freexl-1.0.6         | 48 KB     | : 100% 1.0/1 [00:00<00:00, 24.19it/s]\n","xz-5.2.5             | 341 KB    | : 100% 1.0/1 [00:00<00:00,  8.07it/s]\n","libxcb-1.13          | 395 KB    | : 100% 1.0/1 [00:00<00:00,  8.14it/s]\n","kealib-1.4.7         | 154 KB    | : 100% 1.0/1 [00:00<00:00, 10.11it/s]\n","libblas-3.9.0        | 12 KB     | : 100% 1.0/1 [00:00<00:00, 30.68it/s]\n","lz4-c-1.9.3          | 186 KB    | : 100% 1.0/1 [00:00<00:00,  9.17it/s]\n","libffi-3.3           | 50 KB     | : 100% 1.0/1 [00:00<00:00, 10.29it/s]\n","typing_extensions-3. | 25 KB     | : 100% 1.0/1 [00:00<00:00, 34.94it/s]\n","libuv-1.40.0         | 736 KB    | : 100% 1.0/1 [00:00<00:00,  9.28it/s]\n","freetype-2.10.4      | 596 KB    | : 100% 1.0/1 [00:00<00:00,  8.15it/s]\n","torchvision-0.9.1    | 25.7 MB   | : 100% 1.0/1 [00:04<00:00,  4.58s/it] \n","xorg-libxdmcp-1.1.3  | 19 KB     | : 100% 1.0/1 [00:00<00:00, 24.32it/s]\n","openssl-1.1.1k       | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.25it/s]\n","openh264-2.1.0       | 722 KB    | : 100% 1.0/1 [00:00<00:00,  7.54it/s]\n","libgfortran-ng-7.5.0 | 22 KB     | : 100% 1.0/1 [00:00<00:00, 26.49it/s]\n","lcms2-2.12           | 312 KB    | : 100% 1.0/1 [00:00<00:00, 10.41it/s]\n","python-3.8.10        | 57.7 MB   | : 100% 1.0/1 [00:06<00:00,  6.36s/it]\n","expat-2.4.1          | 182 KB    | : 100% 1.0/1 [00:00<00:00, 16.04it/s]\n","wheel-0.36.2         | 33 KB     | : 100% 1.0/1 [00:00<00:00, 10.14it/s]\n","curl-7.68.0          | 137 KB    | : 100% 1.0/1 [00:00<00:00, 21.03it/s]\n","util-linux-2.36      | 3.4 MB    | : 100% 1.0/1 [00:00<00:00,  1.49it/s]\n","setuptools-52.0.0    | 714 KB    | : 100% 1.0/1 [00:00<00:00,  7.87it/s]\n","sqlite-3.35.4        | 981 KB    | : 100% 1.0/1 [00:00<00:00,  6.24it/s]\n","ld_impl_linux-64-2.3 | 586 KB    | : 100% 1.0/1 [00:00<00:00,  8.27it/s]\n","zstd-1.4.9           | 480 KB    | : 100% 1.0/1 [00:00<00:00,  8.54it/s]\n","zlib-1.2.11          | 103 KB    | : 100% 1.0/1 [00:00<00:00, 10.17it/s]\n","pip-21.1.2           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  4.70it/s]\n","libpq-11.5           | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.17it/s]\n","libtiff-4.2.0        | 502 KB    | : 100% 1.0/1 [00:00<00:00,  8.29it/s]\n","libxml2-2.9.9        | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.91it/s]\n","icu-58.2             | 22.6 MB   | : 100% 1.0/1 [00:03<00:00,  3.08s/it]\n","geos-3.7.1           | 1.6 MB    | : 100% 1.0/1 [00:00<00:00,  2.01it/s]\n","xorg-libxau-1.0.9    | 13 KB     | : 100% 1.0/1 [00:00<00:00, 30.07it/s]\n","lame-3.100           | 323 KB    | : 100% 1.0/1 [00:00<00:00,  9.20it/s]\n","libgcc-ng-9.3.0      | 4.8 MB    | : 100% 1.0/1 [00:00<00:00,  4.61it/s]\n","krb5-1.16.4          | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  3.98it/s]\n","certifi-2021.5.30    | 141 KB    | : 100% 1.0/1 [00:00<00:00, 18.79it/s]\n","intel-openmp-2021.2. | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  7.46it/s]\n","json-c-0.13.1        | 76 KB     | : 100% 1.0/1 [00:00<00:00, 22.37it/s]\n","libuuid-1.0.3        | 15 KB     | : 100% 1.0/1 [00:00<00:00, 11.07it/s]\n","xerces-c-3.2.2       | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.06it/s]\n","giflib-5.1.9         | 108 KB    | : 100% 1.0/1 [00:00<00:00,  7.89it/s]               \n","libwebp-base-1.2.0   | 437 KB    | : 100% 1.0/1 [00:00<00:00,  9.70it/s]\n","mkl-2021.2.0         | 144.3 MB  | : 100% 1.0/1 [00:05<00:00,  5.11s/it]               \n","olefile-0.46         | 31 KB     | : 100% 1.0/1 [00:00<00:00, 27.26it/s]\n","mkl-service-2.3.0    | 57 KB     | : 100% 1.0/1 [00:00<00:00, 10.27it/s]\n","libspatialite-4.3.0a | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.57it/s]\n","python_abi-3.8       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 24.85it/s]\n","bzip2-1.0.8          | 78 KB     | : 100% 1.0/1 [00:00<00:00,  8.79it/s]\n","libkml-1.3.0         | 643 KB    | : 100% 1.0/1 [00:00<00:00,  6.32it/s]\n","jpeg-9b              | 214 KB    | : 100% 1.0/1 [00:00<00:00,  8.99it/s]\n","boost-cpp-1.70.0     | 21.1 MB   | : 100% 1.0/1 [00:06<00:00,  6.15s/it]               \n","liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 31.86it/s]\n","cudatoolkit-10.2.89  | 365.1 MB  | : 100% 1.0/1 [00:11<00:00, 11.03s/it]               \n","libgomp-9.3.0        | 311 KB    | : 100% 1.0/1 [00:00<00:00,  5.56it/s]\n","_libgcc_mutex-0.1    | 2 KB      | : 100% 1.0/1 [00:01<00:00,  1.95s/it]\n","libunistring-0.9.10  | 536 KB    | : 100% 1.0/1 [00:00<00:00, 10.00it/s]\n","readline-8.1         | 362 KB    | : 100% 1.0/1 [00:00<00:00, 11.50it/s]\n","libiconv-1.15        | 721 KB    | : 100% 1.0/1 [00:00<00:00,  8.87it/s]\n","hdf4-4.2.13          | 969 KB    | : 100% 1.0/1 [00:00<00:00,  3.75it/s]\n","pytorch-1.8.1        | 673.4 MB  | : 100% 1.0/1 [01:39<00:00, 99.87s/it]               \n","gmp-6.2.1            | 539 KB    | : 100% 1.0/1 [00:00<00:00, 10.61it/s]\n","glib-2.68.2          | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.83it/s]\n","poppler-data-0.4.10  | 3.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.72it/s]\n","libgdal-2.3.3        | 11.1 MB   | : 100% 1.0/1 [00:00<00:00,  1.15it/s]               \n","libnetcdf-4.6.1      | 833 KB    | : 100% 1.0/1 [00:00<00:00,  9.42it/s]\n","six-1.15.0           | 27 KB     | : 100% 1.0/1 [00:00<00:00, 13.60it/s]\n","mkl_fft-1.3.0        | 180 KB    | : 100% 1.0/1 [00:00<00:00, 11.41it/s]\n","pthread-stubs-0.4    | 5 KB      | : 100% 1.0/1 [00:00<00:00, 29.03it/s]\n","libstdcxx-ng-9.3.0   | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.75it/s]\n","ca-certificates-2021 | 136 KB    | : 100% 1.0/1 [00:00<00:00, 21.46it/s]\n","pillow-8.2.0         | 628 KB    | : 100% 1.0/1 [00:00<00:00, 10.06it/s]\n","_openmp_mutex-4.5    | 22 KB     | : 100% 1.0/1 [00:00<00:00, 19.71it/s]\n","cairo-1.14.12        | 906 KB    | : 100% 1.0/1 [00:00<00:00,  8.87it/s]\n","Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n","Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n","Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n","Installing pip dependencies: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ Ran pip subprocess with arguments:\n","['/usr/local/envs/cell/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/DMNet_Rina/training_codes/condaenv.v68hdi9q.requirements.txt']\n","Pip subprocess output:\n","Collecting absl-py==0.12.0\n","  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n","Collecting affine==2.3.0\n","  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting albumentations==0.4.3\n","  Downloading albumentations-0.4.3.tar.gz (3.2 MB)\n","Collecting astunparse==1.6.3\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting attrs==21.2.0\n","  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n","Collecting cachetools==4.2.2\n","  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n","Collecting chardet==4.0.0\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","Collecting click==8.0.1\n","  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n","Collecting click-plugins==1.1.1\n","  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n","Collecting cligj==0.7.2\n","  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n","Collecting cycler==0.10.0\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting decorator==4.4.2\n","  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n","Collecting fiona==1.8.20\n","  Downloading Fiona-1.8.20-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (15.4 MB)\n","Collecting flatbuffers==1.12\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting gast==0.4.0\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting geopandas==0.9.0\n","  Downloading geopandas-0.9.0-py2.py3-none-any.whl (994 kB)\n","Collecting google-auth==1.31.0\n","  Downloading google_auth-1.31.0-py2.py3-none-any.whl (147 kB)\n","Collecting google-auth-oauthlib==0.4.4\n","  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n","Collecting google-pasta==0.2.0\n","  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Collecting grpcio==1.34.1\n","  Downloading grpcio-1.34.1-cp38-cp38-manylinux2014_x86_64.whl (4.0 MB)\n","Collecting h5py==3.1.0\n","  Downloading h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n","Collecting idna==2.10\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","Collecting imagecodecs==2021.6.8\n","  Downloading imagecodecs-2021.6.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.0 MB)\n","Collecting imagecorruptions==1.1.2\n","  Downloading imagecorruptions-1.1.2-py3-none-any.whl (2.1 MB)\n","Collecting imageio==2.9.0\n","  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n","Collecting imgaug==0.4.0\n","  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n","Collecting keras-nightly==2.5.0.dev2021032900\n","  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n","Collecting keras-preprocessing==1.1.2\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","Collecting kiwisolver==1.3.1\n","  Downloading kiwisolver-1.3.1-cp38-cp38-manylinux1_x86_64.whl (1.2 MB)\n","Collecting markdown==3.3.4\n","  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n","Collecting matplotlib==3.4.2\n","  Downloading matplotlib-3.4.2-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n","Collecting munch==2.5.0\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Collecting networkx==2.5.1\n","  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n","Collecting numpy==1.19.5\n","  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n","Collecting oauthlib==3.1.1\n","  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n","Collecting opencv-python-headless==4.5.2.54\n","  Downloading opencv_python_headless-4.5.2.54-cp38-cp38-manylinux2014_x86_64.whl (38.2 MB)\n","Collecting opt-einsum==3.3.0\n","  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Collecting pandas==1.2.4\n","  Downloading pandas-1.2.4-cp38-cp38-manylinux1_x86_64.whl (9.7 MB)\n","Collecting protobuf==3.17.3\n","  Downloading protobuf-3.17.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","Collecting pyasn1==0.4.8\n","  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","Collecting pyasn1-modules==0.2.8\n","  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","Collecting pyproj==3.1.0\n","  Downloading pyproj-3.1.0-cp38-cp38-manylinux2010_x86_64.whl (6.6 MB)\n","Collecting python-dateutil==2.8.1\n","  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n","Collecting pytz==2021.1\n","  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n","Collecting pywavelets==1.1.1\n","  Downloading PyWavelets-1.1.1-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n","Collecting pyyaml==5.4.1\n","  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n","Collecting rasterio==1.2.4\n","  Downloading rasterio-1.2.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (19.2 MB)\n","Collecting requests==2.25.1\n","  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n","Collecting requests-oauthlib==1.3.0\n","  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n","Collecting rsa==4.7.2\n","  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n","Collecting scikit-image==0.18.1\n","  Downloading scikit_image-0.18.1-cp38-cp38-manylinux1_x86_64.whl (30.2 MB)\n","Collecting scipy==1.6.3\n","  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n","Collecting shapely==1.7.1\n","  Downloading Shapely-1.7.1-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n","Collecting snuggs==1.4.7\n","  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n","Collecting tensorboard==2.5.0\n","  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n","Collecting tensorboard-data-server==0.6.1\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","Collecting tensorboard-plugin-wit==1.8.0\n","  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n","Collecting tensorflow-estimator==2.5.0\n","  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n","Collecting tensorflow-gpu==2.5.0\n","  Downloading tensorflow_gpu-2.5.0-cp38-cp38-manylinux2010_x86_64.whl (454.4 MB)\n","Collecting termcolor==1.1.0\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","Collecting tifffile==2021.6.6\n","  Downloading tifffile-2021.6.6-py3-none-any.whl (168 kB)\n","Collecting tqdm==4.61.0\n","  Downloading tqdm-4.61.0-py2.py3-none-any.whl (75 kB)\n","Collecting urllib3==1.26.5\n","  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n","Collecting werkzeug==2.0.1\n","  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n","Collecting wrapt==1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","Requirement already satisfied: six in /usr/local/envs/cell/lib/python3.8/site-packages (from absl-py==0.12.0->-r /content/DMNet_Rina/training_codes/condaenv.v68hdi9q.requirements.txt (line 1)) (1.15.0)\n","INFO: pip is looking at multiple versions of affine to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of absl-py to determine which version is compatible with other requirements. This could take a while.\n","\n","The conflict is caused by:\n","    The user requested imgaug==0.4.0\n","    albumentations 0.4.3 depends on imgaug<0.2.7 and >=0.2.5\n","\n","To fix this you could try to:\n","1. loosen the range of package versions you've specified\n","2. remove package versions to allow pip attempt to solve the dependency conflict\n","\n","\n","Pip subprocess error:\n","ERROR: Cannot install -r /content/DMNet_Rina/training_codes/condaenv.v68hdi9q.requirements.txt (line 3) and imgaug==0.4.0 because these package versions have conflicting dependencies.\n","ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\n","\n","\b\bfailed\n","\n","CondaEnvException: Pip failed\n","\n","\n","CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n","To initialize your shell, run\n","\n","    $ conda init <SHELL_NAME>\n","\n","Currently supported shells are:\n","  - bash\n","  - fish\n","  - tcsh\n","  - xonsh\n","  - zsh\n","  - powershell\n","\n","See 'conda init --help' for more information and options.\n","\n","IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n","\n","\n"]}],"source":["import os\n","os.chdir(\"/content/DMNet_Rina/training_codes\")\n","!conda env create -f environment.yml\n","!conda activate cell"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1091,"status":"ok","timestamp":1642760751734,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04592796515262324641"},"user_tz":0},"id":"lRftdZGhYplZ","outputId":"c1d33d57-5771-42eb-88b9-d2be22c09779"},"outputs":[{"name":"stdout","output_type":"stream","text":["# conda environments:\n","#\n","base                     /usr/local\n","cell                  *  /usr/local/envs/cell\n","\n"]}],"source":["!source activate cell && conda env list"]},{"cell_type":"markdown","metadata":{"id":"EbwMgqnkcYdj"},"source":["# Place pretrained models in the correct folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-YzTc4M-cX07"},"outputs":[],"source":["!mkdir \"/content/DMNet_Rina/training_codes/models_imagenet\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoCQvA01ck9j"},"outputs":[],"source":["!cp \"/content/drive/MyDrive/Estibaliz Gomez de Mariscal/CELL TRACKING CHALLENGE (CTC)/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/models_imagenet/hrnetv2_w32_imagenet_pretrained.pth\" \"/content/DMNet_Rina/training_codes/models_imagenet/hrnetv2_w32_imagenet_pretrained.pth\""]},{"cell_type":"markdown","metadata":{"id":"HKUQeM5Lc3QK"},"source":["# Place training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wF7xboo3hFoH"},"outputs":[],"source":["!mkdir \"/content/DMNet_Rina/Data\"\n","!mkdir \"/content/DMNet_Rina/Data/train\"\n","\n","!cp -R '/content/drive/MyDrive/Estibaliz Gomez de Mariscal/CELL TRACKING CHALLENGE (CTC)/CTC trainable solutions/Data Estibaliz/PURD-US = ctc288/PURD-US = ctc288 SW/training_scripts/datasets/raw/DIC-C2DH-HeLa' '/content/DMNet_Rina/Data/train'\n","!cp -R '/content/drive/MyDrive/Estibaliz Gomez de Mariscal/CELL TRACKING CHALLENGE (CTC)/CTC trainable solutions/Data Estibaliz/PURD-US = ctc288/DIC-C2DH-HeLa/01' '/content/DMNet_Rina/Data/train/DIC-C2DH-HeLa'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6FpRUTK_c3tG"},"outputs":[],"source":["import os \n","os.chdir(\"/content/DMNet_Rina/training_codes/generate_bash\")\n","!bash \"/content/DMNet_Rina/training_codes/generate_bash/DIC-C2DH-HeLa.sh\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTjE9NEcey8i"},"outputs":[],"source":["!pip install imgaug\n","!pip install imagecodecs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74U7VFJRlvR5"},"outputs":[],"source":["import imgaug\n","imgaug.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"_F8jC2zhdv3Q","outputId":"e036214f-1833-4fac-ec35-709824e9f592"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"name":"stdout","output_type":"stream","text":["{'weightedbcelogitsrina': None, 'weightedjaccardlossrina': None}\n","=> init weights from normal distribution\n","!!!!!!!!!!!!!!!!!!!!!! True\n","=> !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!loading pretrained model /content/DMNet_Rina/training_codes/models_imagenet/hrnetv2_w32_imagenet_pretrained.pth\n","=> loading conv1.weight pretrained model True\n","=> loading bn1.weight pretrained model True\n","=> loading bn1.bias pretrained model True\n","=> loading bn1.running_mean pretrained model True\n","=> loading bn1.running_var pretrained model True\n","=> loading bn1.num_batches_tracked pretrained model True\n","=> loading conv2.weight pretrained model True\n","=> loading bn2.weight pretrained model True\n","=> loading bn2.bias pretrained model True\n","=> loading bn2.running_mean pretrained model True\n","=> loading bn2.running_var pretrained model True\n","=> loading bn2.num_batches_tracked pretrained model True\n","=> loading layer1.0.conv1.weight pretrained model True\n","=> loading layer1.0.bn1.weight pretrained model True\n","=> loading layer1.0.bn1.bias pretrained model True\n","=> loading layer1.0.bn1.running_mean pretrained model True\n","=> loading layer1.0.bn1.running_var pretrained model True\n","=> loading layer1.0.bn1.num_batches_tracked pretrained model True\n","=> loading layer1.0.conv2.weight pretrained model True\n","=> loading layer1.0.bn2.weight pretrained model True\n","=> loading layer1.0.bn2.bias pretrained model True\n","=> loading layer1.0.bn2.running_mean pretrained model True\n","=> loading layer1.0.bn2.running_var pretrained model True\n","=> loading layer1.0.bn2.num_batches_tracked pretrained model True\n","=> loading layer1.0.conv3.weight pretrained model True\n","=> loading layer1.0.bn3.weight pretrained model True\n","=> loading layer1.0.bn3.bias pretrained model True\n","=> loading layer1.0.bn3.running_mean pretrained model True\n","=> loading layer1.0.bn3.running_var pretrained model True\n","=> loading layer1.0.bn3.num_batches_tracked pretrained model True\n","=> loading layer1.0.downsample.0.weight pretrained model True\n","=> loading layer1.0.downsample.1.weight pretrained model True\n","=> loading layer1.0.downsample.1.bias pretrained model True\n","=> loading layer1.0.downsample.1.running_mean pretrained model True\n","=> loading layer1.0.downsample.1.running_var pretrained model True\n","=> loading layer1.0.downsample.1.num_batches_tracked pretrained model True\n","=> loading layer1.1.conv1.weight pretrained model True\n","=> loading layer1.1.bn1.weight pretrained model True\n","=> loading layer1.1.bn1.bias pretrained model True\n","=> loading layer1.1.bn1.running_mean pretrained model True\n","=> loading layer1.1.bn1.running_var pretrained model True\n","=> loading layer1.1.bn1.num_batches_tracked pretrained model True\n","=> loading layer1.1.conv2.weight pretrained model True\n","=> loading layer1.1.bn2.weight pretrained model True\n","=> loading layer1.1.bn2.bias pretrained model True\n","=> loading layer1.1.bn2.running_mean pretrained model True\n","=> loading layer1.1.bn2.running_var pretrained model True\n","=> loading layer1.1.bn2.num_batches_tracked pretrained model True\n","=> loading layer1.1.conv3.weight pretrained model True\n","=> loading layer1.1.bn3.weight pretrained model True\n","=> loading layer1.1.bn3.bias pretrained model True\n","=> loading layer1.1.bn3.running_mean pretrained model True\n","=> loading layer1.1.bn3.running_var pretrained model True\n","=> loading layer1.1.bn3.num_batches_tracked pretrained model True\n","=> loading layer1.2.conv1.weight pretrained model True\n","=> loading layer1.2.bn1.weight pretrained model True\n","=> loading layer1.2.bn1.bias pretrained model True\n","=> loading layer1.2.bn1.running_mean pretrained model True\n","=> loading layer1.2.bn1.running_var pretrained model True\n","=> loading layer1.2.bn1.num_batches_tracked pretrained model True\n","=> loading layer1.2.conv2.weight pretrained model True\n","=> loading layer1.2.bn2.weight pretrained model True\n","=> loading layer1.2.bn2.bias pretrained model True\n","=> loading layer1.2.bn2.running_mean pretrained model True\n","=> loading layer1.2.bn2.running_var pretrained model True\n","=> loading layer1.2.bn2.num_batches_tracked pretrained model True\n","=> loading layer1.2.conv3.weight pretrained model True\n","=> loading layer1.2.bn3.weight pretrained model True\n","=> loading layer1.2.bn3.bias pretrained model True\n","=> loading layer1.2.bn3.running_mean pretrained model True\n","=> loading layer1.2.bn3.running_var pretrained model True\n","=> loading layer1.2.bn3.num_batches_tracked pretrained model True\n","=> loading layer1.3.conv1.weight pretrained model True\n","=> loading layer1.3.bn1.weight pretrained model True\n","=> loading layer1.3.bn1.bias pretrained model True\n","=> loading layer1.3.bn1.running_mean pretrained model True\n","=> loading layer1.3.bn1.running_var pretrained model True\n","=> loading layer1.3.bn1.num_batches_tracked pretrained model True\n","=> loading layer1.3.conv2.weight pretrained model True\n","=> loading layer1.3.bn2.weight pretrained model True\n","=> loading layer1.3.bn2.bias pretrained model True\n","=> loading layer1.3.bn2.running_mean pretrained model True\n","=> loading layer1.3.bn2.running_var pretrained model True\n","=> loading layer1.3.bn2.num_batches_tracked pretrained model True\n","=> loading layer1.3.conv3.weight pretrained model True\n","=> loading layer1.3.bn3.weight pretrained model True\n","=> loading layer1.3.bn3.bias pretrained model True\n","=> loading layer1.3.bn3.running_mean pretrained model True\n","=> loading layer1.3.bn3.running_var pretrained model True\n","=> loading layer1.3.bn3.num_batches_tracked pretrained model True\n","=> loading transition1.0.0.weight pretrained model True\n","=> loading transition1.0.1.weight pretrained model True\n","=> loading transition1.0.1.bias pretrained model True\n","=> loading transition1.0.1.running_mean pretrained model True\n","=> loading transition1.0.1.running_var pretrained model True\n","=> loading transition1.0.1.num_batches_tracked pretrained model True\n","=> loading transition1.1.0.0.weight pretrained model True\n","=> loading transition1.1.0.1.weight pretrained model True\n","=> loading transition1.1.0.1.bias pretrained model True\n","=> loading transition1.1.0.1.running_mean pretrained model True\n","=> loading transition1.1.0.1.running_var pretrained model True\n","=> loading transition1.1.0.1.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.0.0.conv1.weight pretrained model True\n","=> loading stage2.0.branches.0.0.bn1.weight pretrained model True\n","=> loading stage2.0.branches.0.0.bn1.bias pretrained model True\n","=> loading stage2.0.branches.0.0.bn1.running_mean pretrained model True\n","=> loading stage2.0.branches.0.0.bn1.running_var pretrained model True\n","=> loading stage2.0.branches.0.0.bn1.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.0.0.conv2.weight pretrained model True\n","=> loading stage2.0.branches.0.0.bn2.weight pretrained model True\n","=> loading stage2.0.branches.0.0.bn2.bias pretrained model True\n","=> loading stage2.0.branches.0.0.bn2.running_mean pretrained model True\n","=> loading stage2.0.branches.0.0.bn2.running_var pretrained model True\n","=> loading stage2.0.branches.0.0.bn2.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.0.1.conv1.weight pretrained model True\n","=> loading stage2.0.branches.0.1.bn1.weight pretrained model True\n","=> loading stage2.0.branches.0.1.bn1.bias pretrained model True\n","=> loading stage2.0.branches.0.1.bn1.running_mean pretrained model True\n","=> loading stage2.0.branches.0.1.bn1.running_var pretrained model True\n","=> loading stage2.0.branches.0.1.bn1.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.0.1.conv2.weight pretrained model True\n","=> loading stage2.0.branches.0.1.bn2.weight pretrained model True\n","=> loading stage2.0.branches.0.1.bn2.bias pretrained model True\n","=> loading stage2.0.branches.0.1.bn2.running_mean pretrained model True\n","=> loading stage2.0.branches.0.1.bn2.running_var pretrained model True\n","=> loading stage2.0.branches.0.1.bn2.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.0.2.conv1.weight pretrained model True\n","=> loading stage2.0.branches.0.2.bn1.weight pretrained model True\n","=> loading stage2.0.branches.0.2.bn1.bias pretrained model True\n","=> loading stage2.0.branches.0.2.bn1.running_mean pretrained model True\n","=> loading stage2.0.branches.0.2.bn1.running_var pretrained model True\n","=> loading stage2.0.branches.0.2.bn1.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.0.2.conv2.weight pretrained model True\n","=> loading stage2.0.branches.0.2.bn2.weight pretrained model True\n","=> loading stage2.0.branches.0.2.bn2.bias pretrained model True\n","=> loading stage2.0.branches.0.2.bn2.running_mean pretrained model True\n","=> loading stage2.0.branches.0.2.bn2.running_var pretrained model True\n","=> loading stage2.0.branches.0.2.bn2.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.0.3.conv1.weight pretrained model True\n","=> loading stage2.0.branches.0.3.bn1.weight pretrained model True\n","=> loading stage2.0.branches.0.3.bn1.bias pretrained model True\n","=> loading stage2.0.branches.0.3.bn1.running_mean pretrained model True\n","=> loading stage2.0.branches.0.3.bn1.running_var pretrained model True\n","=> loading stage2.0.branches.0.3.bn1.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.0.3.conv2.weight pretrained model True\n","=> loading stage2.0.branches.0.3.bn2.weight pretrained model True\n","=> loading stage2.0.branches.0.3.bn2.bias pretrained model True\n","=> loading stage2.0.branches.0.3.bn2.running_mean pretrained model True\n","=> loading stage2.0.branches.0.3.bn2.running_var pretrained model True\n","=> loading stage2.0.branches.0.3.bn2.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.1.0.conv1.weight pretrained model True\n","=> loading stage2.0.branches.1.0.bn1.weight pretrained model True\n","=> loading stage2.0.branches.1.0.bn1.bias pretrained model True\n","=> loading stage2.0.branches.1.0.bn1.running_mean pretrained model True\n","=> loading stage2.0.branches.1.0.bn1.running_var pretrained model True\n","=> loading stage2.0.branches.1.0.bn1.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.1.0.conv2.weight pretrained model True\n","=> loading stage2.0.branches.1.0.bn2.weight pretrained model True\n","=> loading stage2.0.branches.1.0.bn2.bias pretrained model True\n","=> loading stage2.0.branches.1.0.bn2.running_mean pretrained model True\n","=> loading stage2.0.branches.1.0.bn2.running_var pretrained model True\n","=> loading stage2.0.branches.1.0.bn2.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.1.1.conv1.weight pretrained model True\n","=> loading stage2.0.branches.1.1.bn1.weight pretrained model True\n","=> loading stage2.0.branches.1.1.bn1.bias pretrained model True\n","=> loading stage2.0.branches.1.1.bn1.running_mean pretrained model True\n","=> loading stage2.0.branches.1.1.bn1.running_var pretrained model True\n","=> loading stage2.0.branches.1.1.bn1.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.1.1.conv2.weight pretrained model True\n","=> loading stage2.0.branches.1.1.bn2.weight pretrained model True\n","=> loading stage2.0.branches.1.1.bn2.bias pretrained model True\n","=> loading stage2.0.branches.1.1.bn2.running_mean pretrained model True\n","=> loading stage2.0.branches.1.1.bn2.running_var pretrained model True\n","=> loading stage2.0.branches.1.1.bn2.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.1.2.conv1.weight pretrained model True\n","=> loading stage2.0.branches.1.2.bn1.weight pretrained model True\n","=> loading stage2.0.branches.1.2.bn1.bias pretrained model True\n","=> loading stage2.0.branches.1.2.bn1.running_mean pretrained model True\n","=> loading stage2.0.branches.1.2.bn1.running_var pretrained model True\n","=> loading stage2.0.branches.1.2.bn1.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.1.2.conv2.weight pretrained model True\n","=> loading stage2.0.branches.1.2.bn2.weight pretrained model True\n","=> loading stage2.0.branches.1.2.bn2.bias pretrained model True\n","=> loading stage2.0.branches.1.2.bn2.running_mean pretrained model True\n","=> loading stage2.0.branches.1.2.bn2.running_var pretrained model True\n","=> loading stage2.0.branches.1.2.bn2.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.1.3.conv1.weight pretrained model True\n","=> loading stage2.0.branches.1.3.bn1.weight pretrained model True\n","=> loading stage2.0.branches.1.3.bn1.bias pretrained model True\n","=> loading stage2.0.branches.1.3.bn1.running_mean pretrained model True\n","=> loading stage2.0.branches.1.3.bn1.running_var pretrained model True\n","=> loading stage2.0.branches.1.3.bn1.num_batches_tracked pretrained model True\n","=> loading stage2.0.branches.1.3.conv2.weight pretrained model True\n","=> loading stage2.0.branches.1.3.bn2.weight pretrained model True\n","=> loading stage2.0.branches.1.3.bn2.bias pretrained model True\n","=> loading stage2.0.branches.1.3.bn2.running_mean pretrained model True\n","=> loading stage2.0.branches.1.3.bn2.running_var pretrained model True\n","=> loading stage2.0.branches.1.3.bn2.num_batches_tracked pretrained model True\n","=> loading stage2.0.fuse_layers.0.1.0.weight pretrained model True\n","=> loading stage2.0.fuse_layers.0.1.1.weight pretrained model True\n","=> loading stage2.0.fuse_layers.0.1.1.bias pretrained model True\n","=> loading stage2.0.fuse_layers.0.1.1.running_mean pretrained model True\n","=> loading stage2.0.fuse_layers.0.1.1.running_var pretrained model True\n","=> loading stage2.0.fuse_layers.0.1.1.num_batches_tracked pretrained model True\n","=> loading stage2.0.fuse_layers.1.0.0.0.weight pretrained model True\n","=> loading stage2.0.fuse_layers.1.0.0.1.weight pretrained model True\n","=> loading stage2.0.fuse_layers.1.0.0.1.bias pretrained model True\n","=> loading stage2.0.fuse_layers.1.0.0.1.running_mean pretrained model True\n","=> loading stage2.0.fuse_layers.1.0.0.1.running_var pretrained model True\n","=> loading stage2.0.fuse_layers.1.0.0.1.num_batches_tracked pretrained model True\n","=> loading transition2.2.0.0.weight pretrained model True\n","=> loading transition2.2.0.1.weight pretrained model True\n","=> loading transition2.2.0.1.bias pretrained model True\n","=> loading transition2.2.0.1.running_mean pretrained model True\n","=> loading transition2.2.0.1.running_var pretrained model True\n","=> loading transition2.2.0.1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.0.0.conv1.weight pretrained model True\n","=> loading stage3.0.branches.0.0.bn1.weight pretrained model True\n","=> loading stage3.0.branches.0.0.bn1.bias pretrained model True\n","=> loading stage3.0.branches.0.0.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.0.0.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.0.0.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.0.0.conv2.weight pretrained model True\n","=> loading stage3.0.branches.0.0.bn2.weight pretrained model True\n","=> loading stage3.0.branches.0.0.bn2.bias pretrained model True\n","=> loading stage3.0.branches.0.0.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.0.0.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.0.0.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.0.1.conv1.weight pretrained model True\n","=> loading stage3.0.branches.0.1.bn1.weight pretrained model True\n","=> loading stage3.0.branches.0.1.bn1.bias pretrained model True\n","=> loading stage3.0.branches.0.1.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.0.1.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.0.1.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.0.1.conv2.weight pretrained model True\n","=> loading stage3.0.branches.0.1.bn2.weight pretrained model True\n","=> loading stage3.0.branches.0.1.bn2.bias pretrained model True\n","=> loading stage3.0.branches.0.1.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.0.1.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.0.1.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.0.2.conv1.weight pretrained model True\n","=> loading stage3.0.branches.0.2.bn1.weight pretrained model True\n","=> loading stage3.0.branches.0.2.bn1.bias pretrained model True\n","=> loading stage3.0.branches.0.2.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.0.2.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.0.2.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.0.2.conv2.weight pretrained model True\n","=> loading stage3.0.branches.0.2.bn2.weight pretrained model True\n","=> loading stage3.0.branches.0.2.bn2.bias pretrained model True\n","=> loading stage3.0.branches.0.2.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.0.2.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.0.2.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.0.3.conv1.weight pretrained model True\n","=> loading stage3.0.branches.0.3.bn1.weight pretrained model True\n","=> loading stage3.0.branches.0.3.bn1.bias pretrained model True\n","=> loading stage3.0.branches.0.3.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.0.3.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.0.3.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.0.3.conv2.weight pretrained model True\n","=> loading stage3.0.branches.0.3.bn2.weight pretrained model True\n","=> loading stage3.0.branches.0.3.bn2.bias pretrained model True\n","=> loading stage3.0.branches.0.3.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.0.3.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.0.3.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.1.0.conv1.weight pretrained model True\n","=> loading stage3.0.branches.1.0.bn1.weight pretrained model True\n","=> loading stage3.0.branches.1.0.bn1.bias pretrained model True\n","=> loading stage3.0.branches.1.0.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.1.0.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.1.0.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.1.0.conv2.weight pretrained model True\n","=> loading stage3.0.branches.1.0.bn2.weight pretrained model True\n","=> loading stage3.0.branches.1.0.bn2.bias pretrained model True\n","=> loading stage3.0.branches.1.0.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.1.0.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.1.0.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.1.1.conv1.weight pretrained model True\n","=> loading stage3.0.branches.1.1.bn1.weight pretrained model True\n","=> loading stage3.0.branches.1.1.bn1.bias pretrained model True\n","=> loading stage3.0.branches.1.1.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.1.1.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.1.1.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.1.1.conv2.weight pretrained model True\n","=> loading stage3.0.branches.1.1.bn2.weight pretrained model True\n","=> loading stage3.0.branches.1.1.bn2.bias pretrained model True\n","=> loading stage3.0.branches.1.1.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.1.1.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.1.1.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.1.2.conv1.weight pretrained model True\n","=> loading stage3.0.branches.1.2.bn1.weight pretrained model True\n","=> loading stage3.0.branches.1.2.bn1.bias pretrained model True\n","=> loading stage3.0.branches.1.2.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.1.2.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.1.2.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.1.2.conv2.weight pretrained model True\n","=> loading stage3.0.branches.1.2.bn2.weight pretrained model True\n","=> loading stage3.0.branches.1.2.bn2.bias pretrained model True\n","=> loading stage3.0.branches.1.2.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.1.2.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.1.2.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.1.3.conv1.weight pretrained model True\n","=> loading stage3.0.branches.1.3.bn1.weight pretrained model True\n","=> loading stage3.0.branches.1.3.bn1.bias pretrained model True\n","=> loading stage3.0.branches.1.3.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.1.3.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.1.3.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.1.3.conv2.weight pretrained model True\n","=> loading stage3.0.branches.1.3.bn2.weight pretrained model True\n","=> loading stage3.0.branches.1.3.bn2.bias pretrained model True\n","=> loading stage3.0.branches.1.3.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.1.3.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.1.3.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.2.0.conv1.weight pretrained model True\n","=> loading stage3.0.branches.2.0.bn1.weight pretrained model True\n","=> loading stage3.0.branches.2.0.bn1.bias pretrained model True\n","=> loading stage3.0.branches.2.0.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.2.0.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.2.0.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.2.0.conv2.weight pretrained model True\n","=> loading stage3.0.branches.2.0.bn2.weight pretrained model True\n","=> loading stage3.0.branches.2.0.bn2.bias pretrained model True\n","=> loading stage3.0.branches.2.0.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.2.0.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.2.0.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.2.1.conv1.weight pretrained model True\n","=> loading stage3.0.branches.2.1.bn1.weight pretrained model True\n","=> loading stage3.0.branches.2.1.bn1.bias pretrained model True\n","=> loading stage3.0.branches.2.1.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.2.1.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.2.1.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.2.1.conv2.weight pretrained model True\n","=> loading stage3.0.branches.2.1.bn2.weight pretrained model True\n","=> loading stage3.0.branches.2.1.bn2.bias pretrained model True\n","=> loading stage3.0.branches.2.1.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.2.1.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.2.1.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.2.2.conv1.weight pretrained model True\n","=> loading stage3.0.branches.2.2.bn1.weight pretrained model True\n","=> loading stage3.0.branches.2.2.bn1.bias pretrained model True\n","=> loading stage3.0.branches.2.2.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.2.2.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.2.2.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.2.2.conv2.weight pretrained model True\n","=> loading stage3.0.branches.2.2.bn2.weight pretrained model True\n","=> loading stage3.0.branches.2.2.bn2.bias pretrained model True\n","=> loading stage3.0.branches.2.2.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.2.2.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.2.2.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.2.3.conv1.weight pretrained model True\n","=> loading stage3.0.branches.2.3.bn1.weight pretrained model True\n","=> loading stage3.0.branches.2.3.bn1.bias pretrained model True\n","=> loading stage3.0.branches.2.3.bn1.running_mean pretrained model True\n","=> loading stage3.0.branches.2.3.bn1.running_var pretrained model True\n","=> loading stage3.0.branches.2.3.bn1.num_batches_tracked pretrained model True\n","=> loading stage3.0.branches.2.3.conv2.weight pretrained model True\n","=> loading stage3.0.branches.2.3.bn2.weight pretrained model True\n","=> loading stage3.0.branches.2.3.bn2.bias pretrained model True\n","=> loading stage3.0.branches.2.3.bn2.running_mean pretrained model True\n","=> loading stage3.0.branches.2.3.bn2.running_var pretrained model True\n","=> loading stage3.0.branches.2.3.bn2.num_batches_tracked pretrained model True\n","=> loading stage3.0.fuse_layers.0.1.0.weight pretrained model True\n","=> loading stage3.0.fuse_layers.0.1.1.weight pretrained model True\n","=> loading stage3.0.fuse_layers.0.1.1.bias pretrained model True\n","=> loading stage3.0.fuse_layers.0.1.1.running_mean pretrained model True\n","=> loading stage3.0.fuse_layers.0.1.1.running_var pretrained model True\n","=> loading stage3.0.fuse_layers.0.1.1.num_batches_tracked pretrained model True\n","=> loading stage3.0.fuse_layers.0.2.0.weight pretrained model True\n","=> loading stage3.0.fuse_layers.0.2.1.weight pretrained model True\n","=> loading stage3.0.fuse_layers.0.2.1.bias pretrained model True\n","=> loading stage3.0.fuse_layers.0.2.1.running_mean pretrained model True\n","=> loading stage3.0.fuse_layers.0.2.1.running_var pretrained model True\n","=> loading stage3.0.fuse_layers.0.2.1.num_batches_tracked pretrained model True\n","=> loading stage3.0.fuse_layers.1.0.0.0.weight pretrained model True\n","=> loading stage3.0.fuse_layers.1.0.0.1.weight pretrained model True\n","=> loading stage3.0.fuse_layers.1.0.0.1.bias pretrained model True\n","=> loading stage3.0.fuse_layers.1.0.0.1.running_mean pretrained model True\n","=> loading stage3.0.fuse_layers.1.0.0.1.running_var pretrained model True\n","=> loading stage3.0.fuse_layers.1.0.0.1.num_batches_tracked pretrained model True\n","=> loading stage3.0.fuse_layers.1.2.0.weight pretrained model True\n","=> loading stage3.0.fuse_layers.1.2.1.weight pretrained model True\n","=> loading stage3.0.fuse_layers.1.2.1.bias pretrained model True\n","=> loading stage3.0.fuse_layers.1.2.1.running_mean pretrained model True\n","=> loading stage3.0.fuse_layers.1.2.1.running_var pretrained model True\n","=> loading stage3.0.fuse_layers.1.2.1.num_batches_tracked pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.0.0.weight pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.0.1.weight pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.0.1.bias pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.0.1.running_mean pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.0.1.running_var pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.0.1.num_batches_tracked pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.1.0.weight pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.1.1.weight pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.1.1.bias pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.1.1.running_mean pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.1.1.running_var pretrained model True\n","=> loading stage3.0.fuse_layers.2.0.1.1.num_batches_tracked pretrained model True\n","=> loading stage3.0.fuse_layers.2.1.0.0.weight pretrained model True\n","=> loading stage3.0.fuse_layers.2.1.0.1.weight pretrained model True\n","=> loading stage3.0.fuse_layers.2.1.0.1.bias pretrained model True\n","=> loading stage3.0.fuse_layers.2.1.0.1.running_mean pretrained model True\n","=> loading stage3.0.fuse_layers.2.1.0.1.running_var pretrained model True\n","=> loading stage3.0.fuse_layers.2.1.0.1.num_batches_tracked pretrained model True\n","=> loading transition3.3.0.0.weight pretrained model True\n","=> loading transition3.3.0.1.weight pretrained model True\n","=> loading transition3.3.0.1.bias pretrained model True\n","=> loading transition3.3.0.1.running_mean pretrained model True\n","=> loading transition3.3.0.1.running_var pretrained model True\n","=> loading transition3.3.0.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.0.0.conv1.weight pretrained model True\n","=> loading stage4.0.branches.0.0.bn1.weight pretrained model True\n","=> loading stage4.0.branches.0.0.bn1.bias pretrained model True\n","=> loading stage4.0.branches.0.0.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.0.0.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.0.0.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.0.0.conv2.weight pretrained model True\n","=> loading stage4.0.branches.0.0.bn2.weight pretrained model True\n","=> loading stage4.0.branches.0.0.bn2.bias pretrained model True\n","=> loading stage4.0.branches.0.0.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.0.0.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.0.0.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.0.1.conv1.weight pretrained model True\n","=> loading stage4.0.branches.0.1.bn1.weight pretrained model True\n","=> loading stage4.0.branches.0.1.bn1.bias pretrained model True\n","=> loading stage4.0.branches.0.1.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.0.1.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.0.1.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.0.1.conv2.weight pretrained model True\n","=> loading stage4.0.branches.0.1.bn2.weight pretrained model True\n","=> loading stage4.0.branches.0.1.bn2.bias pretrained model True\n","=> loading stage4.0.branches.0.1.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.0.1.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.0.1.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.0.2.conv1.weight pretrained model True\n","=> loading stage4.0.branches.0.2.bn1.weight pretrained model True\n","=> loading stage4.0.branches.0.2.bn1.bias pretrained model True\n","=> loading stage4.0.branches.0.2.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.0.2.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.0.2.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.0.2.conv2.weight pretrained model True\n","=> loading stage4.0.branches.0.2.bn2.weight pretrained model True\n","=> loading stage4.0.branches.0.2.bn2.bias pretrained model True\n","=> loading stage4.0.branches.0.2.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.0.2.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.0.2.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.0.3.conv1.weight pretrained model True\n","=> loading stage4.0.branches.0.3.bn1.weight pretrained model True\n","=> loading stage4.0.branches.0.3.bn1.bias pretrained model True\n","=> loading stage4.0.branches.0.3.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.0.3.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.0.3.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.0.3.conv2.weight pretrained model True\n","=> loading stage4.0.branches.0.3.bn2.weight pretrained model True\n","=> loading stage4.0.branches.0.3.bn2.bias pretrained model True\n","=> loading stage4.0.branches.0.3.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.0.3.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.0.3.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.1.0.conv1.weight pretrained model True\n","=> loading stage4.0.branches.1.0.bn1.weight pretrained model True\n","=> loading stage4.0.branches.1.0.bn1.bias pretrained model True\n","=> loading stage4.0.branches.1.0.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.1.0.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.1.0.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.1.0.conv2.weight pretrained model True\n","=> loading stage4.0.branches.1.0.bn2.weight pretrained model True\n","=> loading stage4.0.branches.1.0.bn2.bias pretrained model True\n","=> loading stage4.0.branches.1.0.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.1.0.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.1.0.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.1.1.conv1.weight pretrained model True\n","=> loading stage4.0.branches.1.1.bn1.weight pretrained model True\n","=> loading stage4.0.branches.1.1.bn1.bias pretrained model True\n","=> loading stage4.0.branches.1.1.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.1.1.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.1.1.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.1.1.conv2.weight pretrained model True\n","=> loading stage4.0.branches.1.1.bn2.weight pretrained model True\n","=> loading stage4.0.branches.1.1.bn2.bias pretrained model True\n","=> loading stage4.0.branches.1.1.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.1.1.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.1.1.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.1.2.conv1.weight pretrained model True\n","=> loading stage4.0.branches.1.2.bn1.weight pretrained model True\n","=> loading stage4.0.branches.1.2.bn1.bias pretrained model True\n","=> loading stage4.0.branches.1.2.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.1.2.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.1.2.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.1.2.conv2.weight pretrained model True\n","=> loading stage4.0.branches.1.2.bn2.weight pretrained model True\n","=> loading stage4.0.branches.1.2.bn2.bias pretrained model True\n","=> loading stage4.0.branches.1.2.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.1.2.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.1.2.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.1.3.conv1.weight pretrained model True\n","=> loading stage4.0.branches.1.3.bn1.weight pretrained model True\n","=> loading stage4.0.branches.1.3.bn1.bias pretrained model True\n","=> loading stage4.0.branches.1.3.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.1.3.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.1.3.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.1.3.conv2.weight pretrained model True\n","=> loading stage4.0.branches.1.3.bn2.weight pretrained model True\n","=> loading stage4.0.branches.1.3.bn2.bias pretrained model True\n","=> loading stage4.0.branches.1.3.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.1.3.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.1.3.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.2.0.conv1.weight pretrained model True\n","=> loading stage4.0.branches.2.0.bn1.weight pretrained model True\n","=> loading stage4.0.branches.2.0.bn1.bias pretrained model True\n","=> loading stage4.0.branches.2.0.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.2.0.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.2.0.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.2.0.conv2.weight pretrained model True\n","=> loading stage4.0.branches.2.0.bn2.weight pretrained model True\n","=> loading stage4.0.branches.2.0.bn2.bias pretrained model True\n","=> loading stage4.0.branches.2.0.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.2.0.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.2.0.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.2.1.conv1.weight pretrained model True\n","=> loading stage4.0.branches.2.1.bn1.weight pretrained model True\n","=> loading stage4.0.branches.2.1.bn1.bias pretrained model True\n","=> loading stage4.0.branches.2.1.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.2.1.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.2.1.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.2.1.conv2.weight pretrained model True\n","=> loading stage4.0.branches.2.1.bn2.weight pretrained model True\n","=> loading stage4.0.branches.2.1.bn2.bias pretrained model True\n","=> loading stage4.0.branches.2.1.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.2.1.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.2.1.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.2.2.conv1.weight pretrained model True\n","=> loading stage4.0.branches.2.2.bn1.weight pretrained model True\n","=> loading stage4.0.branches.2.2.bn1.bias pretrained model True\n","=> loading stage4.0.branches.2.2.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.2.2.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.2.2.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.2.2.conv2.weight pretrained model True\n","=> loading stage4.0.branches.2.2.bn2.weight pretrained model True\n","=> loading stage4.0.branches.2.2.bn2.bias pretrained model True\n","=> loading stage4.0.branches.2.2.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.2.2.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.2.2.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.2.3.conv1.weight pretrained model True\n","=> loading stage4.0.branches.2.3.bn1.weight pretrained model True\n","=> loading stage4.0.branches.2.3.bn1.bias pretrained model True\n","=> loading stage4.0.branches.2.3.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.2.3.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.2.3.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.2.3.conv2.weight pretrained model True\n","=> loading stage4.0.branches.2.3.bn2.weight pretrained model True\n","=> loading stage4.0.branches.2.3.bn2.bias pretrained model True\n","=> loading stage4.0.branches.2.3.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.2.3.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.2.3.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.3.0.conv1.weight pretrained model True\n","=> loading stage4.0.branches.3.0.bn1.weight pretrained model True\n","=> loading stage4.0.branches.3.0.bn1.bias pretrained model True\n","=> loading stage4.0.branches.3.0.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.3.0.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.3.0.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.3.0.conv2.weight pretrained model True\n","=> loading stage4.0.branches.3.0.bn2.weight pretrained model True\n","=> loading stage4.0.branches.3.0.bn2.bias pretrained model True\n","=> loading stage4.0.branches.3.0.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.3.0.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.3.0.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.3.1.conv1.weight pretrained model True\n","=> loading stage4.0.branches.3.1.bn1.weight pretrained model True\n","=> loading stage4.0.branches.3.1.bn1.bias pretrained model True\n","=> loading stage4.0.branches.3.1.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.3.1.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.3.1.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.3.1.conv2.weight pretrained model True\n","=> loading stage4.0.branches.3.1.bn2.weight pretrained model True\n","=> loading stage4.0.branches.3.1.bn2.bias pretrained model True\n","=> loading stage4.0.branches.3.1.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.3.1.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.3.1.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.3.2.conv1.weight pretrained model True\n","=> loading stage4.0.branches.3.2.bn1.weight pretrained model True\n","=> loading stage4.0.branches.3.2.bn1.bias pretrained model True\n","=> loading stage4.0.branches.3.2.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.3.2.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.3.2.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.3.2.conv2.weight pretrained model True\n","=> loading stage4.0.branches.3.2.bn2.weight pretrained model True\n","=> loading stage4.0.branches.3.2.bn2.bias pretrained model True\n","=> loading stage4.0.branches.3.2.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.3.2.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.3.2.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.3.3.conv1.weight pretrained model True\n","=> loading stage4.0.branches.3.3.bn1.weight pretrained model True\n","=> loading stage4.0.branches.3.3.bn1.bias pretrained model True\n","=> loading stage4.0.branches.3.3.bn1.running_mean pretrained model True\n","=> loading stage4.0.branches.3.3.bn1.running_var pretrained model True\n","=> loading stage4.0.branches.3.3.bn1.num_batches_tracked pretrained model True\n","=> loading stage4.0.branches.3.3.conv2.weight pretrained model True\n","=> loading stage4.0.branches.3.3.bn2.weight pretrained model True\n","=> loading stage4.0.branches.3.3.bn2.bias pretrained model True\n","=> loading stage4.0.branches.3.3.bn2.running_mean pretrained model True\n","=> loading stage4.0.branches.3.3.bn2.running_var pretrained model True\n","=> loading stage4.0.branches.3.3.bn2.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.0.1.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.0.1.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.0.1.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.0.1.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.0.1.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.0.1.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.0.2.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.0.2.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.0.2.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.0.2.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.0.2.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.0.2.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.0.3.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.0.3.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.0.3.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.0.3.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.0.3.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.0.3.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.1.0.0.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.1.0.0.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.1.0.0.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.1.0.0.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.1.0.0.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.1.0.0.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.1.2.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.1.2.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.1.2.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.1.2.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.1.2.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.1.2.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.1.3.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.1.3.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.1.3.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.1.3.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.1.3.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.1.3.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.0.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.0.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.0.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.0.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.0.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.0.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.1.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.1.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.1.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.1.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.1.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.2.0.1.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.2.1.0.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.2.1.0.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.2.1.0.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.2.1.0.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.2.1.0.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.2.1.0.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.2.3.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.2.3.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.2.3.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.2.3.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.2.3.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.2.3.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.0.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.0.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.0.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.0.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.0.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.0.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.1.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.1.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.1.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.1.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.1.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.1.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.2.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.2.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.2.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.2.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.2.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.3.0.2.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.0.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.0.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.0.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.0.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.0.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.0.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.1.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.1.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.1.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.1.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.1.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.3.1.1.1.num_batches_tracked pretrained model True\n","=> loading stage4.0.fuse_layers.3.2.0.0.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.2.0.1.weight pretrained model True\n","=> loading stage4.0.fuse_layers.3.2.0.1.bias pretrained model True\n","=> loading stage4.0.fuse_layers.3.2.0.1.running_mean pretrained model True\n","=> loading stage4.0.fuse_layers.3.2.0.1.running_var pretrained model True\n","=> loading stage4.0.fuse_layers.3.2.0.1.num_batches_tracked pretrained model True\n","Beginning training epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"]},{"name":"stdout","output_type":"stream","text":["    loss at batch 0: 10.831174850463867\n","    loss at batch 1: 10.523796081542969\n","    loss at batch 2: 10.150823593139648\n","    loss at batch 3: 10.085697174072266\n","    loss at batch 4: 10.322216987609863\n","epoch time 6.219829320907593\n","\n","    Validation loss at epoch 0: 10.740522384643555\n","\n","Beginning training epoch 1\n","    loss at batch 0: 9.777454376220703\n","    loss at batch 1: 9.967020988464355\n","    loss at batch 2: 9.888264656066895\n","    loss at batch 3: 9.902097702026367\n","    loss at batch 4: 9.525444984436035\n","epoch time 5.895767688751221\n","Beginning training epoch 2\n","    loss at batch 0: 9.039746284484863\n","    loss at batch 1: 9.7371187210083\n","    loss at batch 2: 8.911057472229004\n","    loss at batch 3: 9.144909858703613\n","    loss at batch 4: 11.207411766052246\n","epoch time 5.919726133346558\n","Beginning training epoch 3\n","    loss at batch 0: 8.48757266998291\n","    loss at batch 1: 9.157302856445312\n","    loss at batch 2: 8.862189292907715\n","    loss at batch 3: 8.5379638671875\n","    loss at batch 4: 9.479804039001465\n","epoch time 5.7874345779418945\n","Beginning training epoch 4\n","    loss at batch 0: 8.1249361038208\n","    loss at batch 1: 8.173916816711426\n","    loss at batch 2: 8.541617393493652\n","    loss at batch 3: 7.867980003356934\n","    loss at batch 4: 8.389457702636719\n","epoch time 5.75818133354187\n","Beginning training epoch 5\n","    loss at batch 0: 8.059469223022461\n","    loss at batch 1: 7.7286481857299805\n","    loss at batch 2: 7.841618537902832\n","    loss at batch 3: 8.134581565856934\n","    loss at batch 4: 8.731019973754883\n","epoch time 5.861112833023071\n","\n","    Validation loss at epoch 5: 10.421107292175293\n","\n","Beginning training epoch 6\n","    loss at batch 0: 8.203056335449219\n","    loss at batch 1: 8.175922393798828\n","    loss at batch 2: 7.809791564941406\n","    loss at batch 3: 7.156327724456787\n","    loss at batch 4: 7.275696754455566\n","epoch time 5.897828578948975\n","Beginning training epoch 7\n","    loss at batch 0: 6.485211372375488\n","    loss at batch 1: 7.983083724975586\n","    loss at batch 2: 7.774998664855957\n","    loss at batch 3: 6.6934919357299805\n","    loss at batch 4: 7.14130163192749\n","epoch time 5.718449831008911\n","Beginning training epoch 8\n","    loss at batch 0: 6.938321113586426\n","    loss at batch 1: 8.042776107788086\n","    loss at batch 2: 7.482004165649414\n","    loss at batch 3: 6.439741134643555\n","    loss at batch 4: 7.75650691986084\n","epoch time 5.70149040222168\n","Beginning training epoch 9\n","    loss at batch 0: 6.796799182891846\n","    loss at batch 1: 7.424434661865234\n","    loss at batch 2: 6.681303977966309\n","    loss at batch 3: 5.971338748931885\n","    loss at batch 4: 6.276397705078125\n","epoch time 5.717256784439087\n","Beginning training epoch 10\n","    loss at batch 0: 6.526758670806885\n","    loss at batch 1: 6.670563697814941\n","    loss at batch 2: 5.914744853973389\n","    loss at batch 3: 6.307579517364502\n","    loss at batch 4: 7.1531548500061035\n","epoch time 6.008105993270874\n","\n","    Validation loss at epoch 10: 10.61490249633789\n","\n","Beginning training epoch 11\n","    loss at batch 0: 6.018383026123047\n","    loss at batch 1: 5.956302642822266\n","    loss at batch 2: 5.547881126403809\n","    loss at batch 3: 5.71844482421875\n","    loss at batch 4: 6.815162658691406\n","epoch time 5.893538951873779\n","Beginning training epoch 12\n","    loss at batch 0: 6.203975677490234\n","    loss at batch 1: 6.051485061645508\n","    loss at batch 2: 5.649290561676025\n","    loss at batch 3: 5.674063682556152\n","    loss at batch 4: 7.894186496734619\n","epoch time 5.783216714859009\n","Beginning training epoch 13\n","    loss at batch 0: 6.138942718505859\n","    loss at batch 1: 6.1787800788879395\n","    loss at batch 2: 6.050644874572754\n","    loss at batch 3: 4.617303848266602\n","    loss at batch 4: 7.459357261657715\n","epoch time 5.87580132484436\n","Beginning training epoch 14\n","    loss at batch 0: 5.384920597076416\n","    loss at batch 1: 5.870217323303223\n","    loss at batch 2: 6.014206886291504\n","    loss at batch 3: 5.114092826843262\n","    loss at batch 4: 6.298971176147461\n","epoch time 5.795822858810425\n","Beginning training epoch 15\n","    loss at batch 0: 5.542745590209961\n","    loss at batch 1: 4.498330593109131\n","    loss at batch 2: 5.467645645141602\n","    loss at batch 3: 4.867514133453369\n","    loss at batch 4: 5.505640983581543\n","epoch time 5.769036531448364\n","\n","    Validation loss at epoch 15: 10.167083740234375\n","\n","Beginning training epoch 16\n","    loss at batch 0: 5.294102191925049\n","    loss at batch 1: 5.192687511444092\n","    loss at batch 2: 5.232005596160889\n","    loss at batch 3: 5.732458114624023\n","    loss at batch 4: 4.300563335418701\n","epoch time 5.936159610748291\n","Beginning training epoch 17\n","    loss at batch 0: 5.266329288482666\n","    loss at batch 1: 5.045157432556152\n","    loss at batch 2: 4.476030349731445\n","    loss at batch 3: 4.506464958190918\n","    loss at batch 4: 4.618293285369873\n","epoch time 5.960423469543457\n","Beginning training epoch 18\n","    loss at batch 0: 5.482126712799072\n","    loss at batch 1: 4.110013484954834\n","    loss at batch 2: 5.118204116821289\n","    loss at batch 3: 4.533060073852539\n","    loss at batch 4: 9.721051216125488\n","epoch time 5.7696428298950195\n","Beginning training epoch 19\n","    loss at batch 0: 5.303779125213623\n","    loss at batch 1: 4.914234161376953\n","    loss at batch 2: 4.4869279861450195\n","    loss at batch 3: 4.051679611206055\n","    loss at batch 4: 4.3455047607421875\n","epoch time 5.747789144515991\n","Beginning training epoch 20\n","    loss at batch 0: 5.303576469421387\n","    loss at batch 1: 4.293177127838135\n","    loss at batch 2: 3.8450746536254883\n","    loss at batch 3: 5.237062454223633\n","    loss at batch 4: 9.855525970458984\n","epoch time 5.846744060516357\n","\n","    Validation loss at epoch 20: 10.02323055267334\n","\n","Beginning training epoch 21\n","    loss at batch 0: 4.718062877655029\n","    loss at batch 1: 4.139003753662109\n","    loss at batch 2: 4.44587516784668\n","    loss at batch 3: 5.006406784057617\n","    loss at batch 4: 5.378678798675537\n","epoch time 5.865271806716919\n","Beginning training epoch 22\n","    loss at batch 0: 4.718481063842773\n","    loss at batch 1: 4.335319995880127\n","    loss at batch 2: 4.509091854095459\n","    loss at batch 3: 5.0898756980896\n","    loss at batch 4: 3.372462511062622\n","epoch time 5.866705656051636\n","Beginning training epoch 23\n","    loss at batch 0: 4.785285472869873\n","    loss at batch 1: 5.392025470733643\n","    loss at batch 2: 4.4982171058654785\n","    loss at batch 3: 4.594270706176758\n","    loss at batch 4: 4.168758392333984\n","epoch time 5.880005836486816\n","Beginning training epoch 24\n","    loss at batch 0: 4.573768615722656\n","    loss at batch 1: 4.267442226409912\n","    loss at batch 2: 4.608932971954346\n","    loss at batch 3: 4.995876312255859\n","    loss at batch 4: 4.330103874206543\n","epoch time 5.7915732860565186\n","Beginning training epoch 25\n","    loss at batch 0: 4.244356155395508\n","    loss at batch 1: 3.7674753665924072\n","    loss at batch 2: 3.7633790969848633\n","    loss at batch 3: 5.960273265838623\n","    loss at batch 4: 3.7353837490081787\n","epoch time 5.822173833847046\n","\n","    Validation loss at epoch 25: 9.855169296264648\n","\n","Beginning training epoch 26\n","    loss at batch 0: 4.959618091583252\n","    loss at batch 1: 4.020261287689209\n","    loss at batch 2: 3.7852530479431152\n","    loss at batch 3: 5.721199035644531\n","    loss at batch 4: 4.934513568878174\n","epoch time 6.0205018520355225\n","Beginning training epoch 27\n","    loss at batch 0: 4.238000869750977\n","    loss at batch 1: 4.264739990234375\n","    loss at batch 2: 3.948894500732422\n","    loss at batch 3: 3.9746816158294678\n","    loss at batch 4: 4.815330505371094\n","epoch time 5.848722219467163\n","Beginning training epoch 28\n","    loss at batch 0: 3.938631534576416\n","    loss at batch 1: 5.08381462097168\n","    loss at batch 2: 4.892148971557617\n","    loss at batch 3: 3.7377119064331055\n","    loss at batch 4: 4.147429943084717\n","epoch time 5.810150384902954\n","Beginning training epoch 29\n","    loss at batch 0: 4.768171787261963\n","    loss at batch 1: 4.41122579574585\n","    loss at batch 2: 4.212887763977051\n","    loss at batch 3: 4.729477882385254\n","    loss at batch 4: 5.025550842285156\n","epoch time 5.812295436859131\n","Beginning training epoch 30\n","    loss at batch 0: 4.640880584716797\n","    loss at batch 1: 3.9506194591522217\n","    loss at batch 2: 3.6892282962799072\n","    loss at batch 3: 5.028943061828613\n","    loss at batch 4: 3.720620632171631\n","epoch time 5.8671300411224365\n","\n","    Validation loss at epoch 30: 9.377992630004883\n","\n","Beginning training epoch 31\n","    loss at batch 0: 4.294105529785156\n","    loss at batch 1: 4.4037909507751465\n","    loss at batch 2: 3.142975330352783\n","    loss at batch 3: 3.707955837249756\n","    loss at batch 4: 4.246875286102295\n","epoch time 6.017398357391357\n","Beginning training epoch 32\n","    loss at batch 0: 3.3552968502044678\n","    loss at batch 1: 4.363890171051025\n","    loss at batch 2: 3.4817209243774414\n","    loss at batch 3: 3.418783187866211\n","    loss at batch 4: 2.836341619491577\n","epoch time 5.856751203536987\n","Beginning training epoch 33\n","    loss at batch 0: 3.255296468734741\n","    loss at batch 1: 3.3347907066345215\n","    loss at batch 2: 3.9199845790863037\n","    loss at batch 3: 2.93251895904541\n","    loss at batch 4: 3.204266309738159\n","epoch time 5.822398662567139\n","Beginning training epoch 34\n","    loss at batch 0: 5.920415878295898\n","    loss at batch 1: 3.172828435897827\n","    loss at batch 2: 2.9135961532592773\n","    loss at batch 3: 3.8852908611297607\n","    loss at batch 4: 2.8602211475372314\n","epoch time 5.762075901031494\n","Beginning training epoch 35\n","    loss at batch 0: 3.5080180168151855\n","    loss at batch 1: 3.4585251808166504\n","    loss at batch 2: 3.782857894897461\n","    loss at batch 3: 4.858395099639893\n","    loss at batch 4: 3.398277521133423\n","epoch time 5.88090181350708\n","\n","    Validation loss at epoch 35: 8.98980712890625\n","\n","Beginning training epoch 36\n","    loss at batch 0: 4.377715110778809\n","    loss at batch 1: 3.6948533058166504\n","    loss at batch 2: 4.718007564544678\n","    loss at batch 3: 4.366502285003662\n","    loss at batch 4: 3.224882125854492\n","epoch time 5.80517840385437\n","Beginning training epoch 37\n","    loss at batch 0: 3.1886582374572754\n","    loss at batch 1: 3.61844539642334\n","    loss at batch 2: 3.3243088722229004\n","    loss at batch 3: 3.491386890411377\n","    loss at batch 4: 4.0535688400268555\n","epoch time 5.863096237182617\n","Beginning training epoch 38\n","    loss at batch 0: 4.86299467086792\n","    loss at batch 1: 3.3891687393188477\n","    loss at batch 2: 3.9582810401916504\n","    loss at batch 3: 5.258114814758301\n","    loss at batch 4: 3.637094736099243\n","epoch time 5.831197500228882\n","Beginning training epoch 39\n","    loss at batch 0: 3.7946574687957764\n","    loss at batch 1: 3.6850218772888184\n","    loss at batch 2: 4.2781476974487305\n","    loss at batch 3: 4.244997501373291\n","    loss at batch 4: 9.984848976135254\n","epoch time 5.750757455825806\n","Beginning training epoch 40\n","    loss at batch 0: 3.1041457653045654\n","    loss at batch 1: 3.3270821571350098\n","    loss at batch 2: 3.771632432937622\n","    loss at batch 3: 3.796905755996704\n","    loss at batch 4: 6.214365005493164\n","epoch time 5.862383604049683\n","\n","    Validation loss at epoch 40: 8.343204498291016\n","\n","Beginning training epoch 41\n","    loss at batch 0: 4.706119537353516\n","    loss at batch 1: 3.706192970275879\n","    loss at batch 2: 3.2193541526794434\n","    loss at batch 3: 4.42994499206543\n","    loss at batch 4: 4.4822797775268555\n","epoch time 5.847773313522339\n","Beginning training epoch 42\n","    loss at batch 0: 3.3625261783599854\n","    loss at batch 1: 4.987565994262695\n","    loss at batch 2: 3.90584135055542\n","    loss at batch 3: 4.164408206939697\n","    loss at batch 4: 3.4982848167419434\n","epoch time 5.806097745895386\n","Beginning training epoch 43\n","    loss at batch 0: 4.877298355102539\n","    loss at batch 1: 4.062578201293945\n","    loss at batch 2: 3.1022143363952637\n","    loss at batch 3: 3.5075628757476807\n","    loss at batch 4: 4.136538505554199\n","epoch time 5.805913925170898\n","Beginning training epoch 44\n","    loss at batch 0: 4.4484429359436035\n","    loss at batch 1: 3.3296937942504883\n","    loss at batch 2: 3.593280553817749\n","    loss at batch 3: 3.7830891609191895\n","    loss at batch 4: 3.2930264472961426\n","epoch time 5.779939889907837\n","Beginning training epoch 45\n","    loss at batch 0: 3.773836851119995\n","    loss at batch 1: 3.9142632484436035\n","    loss at batch 2: 3.0129668712615967\n","    loss at batch 3: 3.526907444000244\n","    loss at batch 4: 2.8177595138549805\n","epoch time 5.749138593673706\n","\n","    Validation loss at epoch 45: 8.207959175109863\n","\n","Beginning training epoch 46\n","    loss at batch 0: 3.9819540977478027\n","    loss at batch 1: 4.263406753540039\n","    loss at batch 2: 3.09836745262146\n","    loss at batch 3: 3.600172519683838\n","    loss at batch 4: 4.07888650894165\n","epoch time 5.815859079360962\n","Beginning training epoch 47\n","    loss at batch 0: 4.449010848999023\n","    loss at batch 1: 3.6558337211608887\n","    loss at batch 2: 3.230257034301758\n","    loss at batch 3: 4.133202075958252\n","    loss at batch 4: 8.303813934326172\n","epoch time 5.852615118026733\n","Beginning training epoch 48\n","    loss at batch 0: 3.9701266288757324\n","    loss at batch 1: 3.309197425842285\n","    loss at batch 2: 4.2452850341796875\n","    loss at batch 3: 3.4906320571899414\n","    loss at batch 4: 4.884984970092773\n","epoch time 5.922236680984497\n","Beginning training epoch 49\n","    loss at batch 0: 4.180960178375244\n","    loss at batch 1: 4.379397392272949\n","    loss at batch 2: 3.8041484355926514\n","    loss at batch 3: 3.1263458728790283\n","    loss at batch 4: 3.7225148677825928\n","epoch time 5.828463315963745\n","Beginning training epoch 50\n","    loss at batch 0: 3.5892422199249268\n","    loss at batch 1: 3.0006072521209717\n","    loss at batch 2: 2.797337055206299\n","    loss at batch 3: 3.4090576171875\n","    loss at batch 4: 2.4812121391296387\n","epoch time 5.730780839920044\n","\n","    Validation loss at epoch 50: 7.274196624755859\n","\n","Beginning training epoch 51\n","    loss at batch 0: 4.280285835266113\n","    loss at batch 1: 4.006053924560547\n","    loss at batch 2: 3.650240659713745\n","    loss at batch 3: 4.701505661010742\n","    loss at batch 4: 4.00210428237915\n","epoch time 5.8526082038879395\n","Beginning training epoch 52\n","    loss at batch 0: 3.546051502227783\n","    loss at batch 1: 3.4684529304504395\n","    loss at batch 2: 4.057255744934082\n","    loss at batch 3: 3.2021713256835938\n","    loss at batch 4: 4.573232650756836\n","epoch time 5.854351282119751\n","Beginning training epoch 53\n","    loss at batch 0: 3.5201992988586426\n","    loss at batch 1: 3.5771477222442627\n","    loss at batch 2: 3.948193073272705\n","    loss at batch 3: 3.2889621257781982\n","    loss at batch 4: 4.106282711029053\n","epoch time 5.918837547302246\n","Beginning training epoch 54\n","    loss at batch 0: 3.41753888130188\n","    loss at batch 1: 3.5043110847473145\n","    loss at batch 2: 4.489941120147705\n","    loss at batch 3: 3.2253642082214355\n","    loss at batch 4: 3.120954751968384\n","epoch time 5.978047132492065\n","Beginning training epoch 55\n","    loss at batch 0: 3.3007330894470215\n","    loss at batch 1: 3.0275256633758545\n","    loss at batch 2: 4.018026828765869\n","    loss at batch 3: 2.7631778717041016\n","    loss at batch 4: 3.2399888038635254\n","epoch time 5.822825908660889\n","\n","    Validation loss at epoch 55: 6.906981945037842\n","\n","Beginning training epoch 56\n","    loss at batch 0: 3.1542482376098633\n","    loss at batch 1: 2.8645293712615967\n","    loss at batch 2: 3.1090340614318848\n","    loss at batch 3: 3.6738905906677246\n","    loss at batch 4: 11.982156753540039\n","epoch time 5.799375057220459\n","Beginning training epoch 57\n","    loss at batch 0: 2.4581713676452637\n","    loss at batch 1: 3.0707039833068848\n","    loss at batch 2: 4.085281848907471\n","    loss at batch 3: 3.5758910179138184\n","    loss at batch 4: 4.671751022338867\n","epoch time 5.7111496925354\n","Beginning training epoch 58\n","    loss at batch 0: 4.61854887008667\n","    loss at batch 1: 3.3691418170928955\n","    loss at batch 2: 2.928006887435913\n","    loss at batch 3: 3.980929374694824\n","    loss at batch 4: 2.4005775451660156\n","epoch time 5.869866371154785\n","Beginning training epoch 59\n","    loss at batch 0: 4.41141939163208\n","    loss at batch 1: 2.760563850402832\n","    loss at batch 2: 3.7102792263031006\n","    loss at batch 3: 3.429178237915039\n","    loss at batch 4: 3.4889633655548096\n","epoch time 5.754509210586548\n","Beginning training epoch 60\n","    loss at batch 0: 4.029701232910156\n","    loss at batch 1: 3.368211269378662\n","    loss at batch 2: 3.145514488220215\n","    loss at batch 3: 3.331714630126953\n","    loss at batch 4: 5.314539909362793\n","epoch time 5.796591281890869\n","\n","    Validation loss at epoch 60: 5.805480003356934\n","\n","Beginning training epoch 61\n","    loss at batch 0: 2.1492035388946533\n","    loss at batch 1: 3.5626344680786133\n","    loss at batch 2: 3.708568572998047\n","    loss at batch 3: 3.3108983039855957\n","    loss at batch 4: 3.4015040397644043\n","epoch time 5.944450378417969\n","Beginning training epoch 62\n","    loss at batch 0: 2.8001227378845215\n","    loss at batch 1: 3.956634521484375\n","    loss at batch 2: 3.6203479766845703\n","    loss at batch 3: 3.4587314128875732\n","    loss at batch 4: 5.169663429260254\n","epoch time 5.857504844665527\n","Beginning training epoch 63\n","    loss at batch 0: 3.9064362049102783\n","    loss at batch 1: 3.597520589828491\n","    loss at batch 2: 3.360854148864746\n","    loss at batch 3: 2.995553970336914\n","    loss at batch 4: 3.7082271575927734\n","epoch time 5.792792320251465\n","Beginning training epoch 64\n","    loss at batch 0: 3.4275553226470947\n","    loss at batch 1: 2.919954299926758\n","    loss at batch 2: 3.2538938522338867\n","    loss at batch 3: 4.07378625869751\n","    loss at batch 4: 4.097457408905029\n","epoch time 5.73974609375\n","Beginning training epoch 65\n","    loss at batch 0: 2.8879623413085938\n","    loss at batch 1: 3.8030898571014404\n","    loss at batch 2: 3.8677151203155518\n","    loss at batch 3: 3.410259246826172\n","    loss at batch 4: 4.08784818649292\n","epoch time 5.905005216598511\n","\n","    Validation loss at epoch 65: 5.2417120933532715\n","\n","Beginning training epoch 66\n","    loss at batch 0: 3.322762966156006\n","    loss at batch 1: 3.956709861755371\n","    loss at batch 2: 3.5719785690307617\n","    loss at batch 3: 3.252425193786621\n","    loss at batch 4: 3.0324699878692627\n","epoch time 5.939443349838257\n","Beginning training epoch 67\n","    loss at batch 0: 3.2261648178100586\n","    loss at batch 1: 3.445316791534424\n","    loss at batch 2: 3.3778247833251953\n","    loss at batch 3: 2.6209018230438232\n","    loss at batch 4: 6.05419921875\n","epoch time 5.761859655380249\n","Beginning training epoch 68\n","    loss at batch 0: 2.925095796585083\n","    loss at batch 1: 3.3219103813171387\n","    loss at batch 2: 2.766146659851074\n","    loss at batch 3: 3.7132842540740967\n","    loss at batch 4: 3.1999340057373047\n","epoch time 5.795584201812744\n","Beginning training epoch 69\n","    loss at batch 0: 4.039191246032715\n","    loss at batch 1: 2.8204336166381836\n","    loss at batch 2: 3.1824982166290283\n","    loss at batch 3: 2.922161817550659\n","    loss at batch 4: 2.5776937007904053\n","epoch time 5.841309070587158\n","Beginning training epoch 70\n","    loss at batch 0: 3.1556684970855713\n","    loss at batch 1: 3.001127004623413\n","    loss at batch 2: 2.7838757038116455\n","    loss at batch 3: 3.395131826400757\n","    loss at batch 4: 3.9097213745117188\n","epoch time 5.715343236923218\n","\n","    Validation loss at epoch 70: 5.752575874328613\n","\n","Beginning training epoch 71\n","    loss at batch 0: 3.091848373413086\n","    loss at batch 1: 2.612455368041992\n","    loss at batch 2: 3.5544350147247314\n","    loss at batch 3: 3.716848134994507\n","    loss at batch 4: 2.0743818283081055\n","epoch time 5.851733446121216\n","Beginning training epoch 72\n","    loss at batch 0: 3.5673599243164062\n","    loss at batch 1: 2.901109457015991\n","    loss at batch 2: 4.478890895843506\n","    loss at batch 3: 3.1922569274902344\n","    loss at batch 4: 4.387229919433594\n","epoch time 5.71883749961853\n","Beginning training epoch 73\n","    loss at batch 0: 3.089233875274658\n","    loss at batch 1: 3.2702839374542236\n","    loss at batch 2: 3.0542216300964355\n","    loss at batch 3: 4.210967540740967\n","    loss at batch 4: 2.9187562465667725\n","epoch time 5.781583070755005\n","Beginning training epoch 74\n","    loss at batch 0: 3.158832550048828\n","    loss at batch 1: 3.1817433834075928\n","    loss at batch 2: 3.452112913131714\n","    loss at batch 3: 2.979621410369873\n","    loss at batch 4: 3.1410105228424072\n","epoch time 5.911699533462524\n","Beginning training epoch 75\n","    loss at batch 0: 3.0730221271514893\n","    loss at batch 1: 2.7474381923675537\n","    loss at batch 2: 3.7406845092773438\n","    loss at batch 3: 4.185662269592285\n","    loss at batch 4: 4.48618221282959\n","epoch time 5.880725622177124\n","\n","    Validation loss at epoch 75: 5.21949577331543\n","\n","Beginning training epoch 76\n","    loss at batch 0: 2.749730110168457\n","    loss at batch 1: 3.5446348190307617\n","    loss at batch 2: 2.80362606048584\n","    loss at batch 3: 2.672330856323242\n","    loss at batch 4: 2.160646677017212\n","epoch time 5.858816146850586\n","Beginning training epoch 77\n","    loss at batch 0: 2.654539108276367\n","    loss at batch 1: 2.821943759918213\n","    loss at batch 2: 3.3868603706359863\n","    loss at batch 3: 3.2930383682250977\n","    loss at batch 4: 2.8986239433288574\n","epoch time 5.846174001693726\n","Beginning training epoch 78\n","    loss at batch 0: 2.904771327972412\n","    loss at batch 1: 3.1974234580993652\n","    loss at batch 2: 3.0671842098236084\n","    loss at batch 3: 3.459061622619629\n","    loss at batch 4: 2.124356508255005\n","epoch time 5.837878942489624\n","Beginning training epoch 79\n","    loss at batch 0: 3.026545524597168\n","    loss at batch 1: 3.8278796672821045\n","    loss at batch 2: 2.627229928970337\n","    loss at batch 3: 3.2344577312469482\n","    loss at batch 4: 4.514890193939209\n","epoch time 5.853820562362671\n","Beginning training epoch 80\n","    loss at batch 0: 3.842816114425659\n","    loss at batch 1: 3.103743553161621\n","    loss at batch 2: 2.831556558609009\n","    loss at batch 3: 3.2649435997009277\n","    loss at batch 4: 2.855381488800049\n","epoch time 5.847747564315796\n","\n","    Validation loss at epoch 80: 5.48952054977417\n","\n","Beginning training epoch 81\n","    loss at batch 0: 2.768894672393799\n","    loss at batch 1: 2.997892141342163\n","    loss at batch 2: 2.920154571533203\n","    loss at batch 3: 3.9202494621276855\n","    loss at batch 4: 2.904838800430298\n","epoch time 5.79030704498291\n","Beginning training epoch 82\n","    loss at batch 0: 3.20963454246521\n","    loss at batch 1: 3.352541208267212\n","    loss at batch 2: 3.3045973777770996\n","    loss at batch 3: 3.1445796489715576\n","    loss at batch 4: 2.6830129623413086\n","epoch time 5.774873733520508\n","Beginning training epoch 83\n","    loss at batch 0: 3.2775449752807617\n","    loss at batch 1: 3.0442442893981934\n","    loss at batch 2: 2.9341654777526855\n","    loss at batch 3: 3.423856735229492\n","    loss at batch 4: 3.168182373046875\n","epoch time 5.825397253036499\n","Beginning training epoch 84\n","    loss at batch 0: 4.2668561935424805\n","    loss at batch 1: 2.6207494735717773\n","    loss at batch 2: 2.791877031326294\n","    loss at batch 3: 2.9492130279541016\n","    loss at batch 4: 3.642418622970581\n","epoch time 5.862345933914185\n","Beginning training epoch 85\n","    loss at batch 0: 2.71085262298584\n","    loss at batch 1: 3.041853189468384\n","    loss at batch 2: 2.5690908432006836\n","    loss at batch 3: 2.4666948318481445\n","    loss at batch 4: 5.06840705871582\n","epoch time 5.916675329208374\n","\n","    Validation loss at epoch 85: 3.854034423828125\n","\n","Beginning training epoch 86\n","    loss at batch 0: 2.485132932662964\n","    loss at batch 1: 3.3781492710113525\n","    loss at batch 2: 2.88857102394104\n","    loss at batch 3: 3.1790144443511963\n","    loss at batch 4: 4.745725154876709\n","epoch time 5.894906759262085\n","Beginning training epoch 87\n","    loss at batch 0: 3.291281223297119\n","    loss at batch 1: 2.620657444000244\n","    loss at batch 2: 4.5785651206970215\n","    loss at batch 3: 2.622830629348755\n","    loss at batch 4: 2.631633758544922\n","epoch time 5.911347150802612\n","Beginning training epoch 88\n","    loss at batch 0: 3.126492500305176\n","    loss at batch 1: 3.0126404762268066\n","    loss at batch 2: 2.13272762298584\n","    loss at batch 3: 2.8567323684692383\n","    loss at batch 4: 2.559906244277954\n","epoch time 5.920505046844482\n","Beginning training epoch 89\n","    loss at batch 0: 3.0374441146850586\n","    loss at batch 1: 3.080317497253418\n","    loss at batch 2: 2.958721876144409\n","    loss at batch 3: 3.378541946411133\n","    loss at batch 4: 4.070653438568115\n","epoch time 5.9200239181518555\n","Beginning training epoch 90\n","    loss at batch 0: 2.9642715454101562\n","    loss at batch 1: 2.342050790786743\n","    loss at batch 2: 3.2041473388671875\n","    loss at batch 3: 2.7042086124420166\n","    loss at batch 4: 3.3715453147888184\n","epoch time 5.7701027393341064\n","\n","    Validation loss at epoch 90: 3.5634384155273438\n","\n","Beginning training epoch 91\n","    loss at batch 0: 2.8759026527404785\n","    loss at batch 1: 2.442939043045044\n","    loss at batch 2: 3.233013391494751\n","    loss at batch 3: 2.4855384826660156\n","    loss at batch 4: 1.6484049558639526\n","epoch time 5.808058738708496\n","Beginning training epoch 92\n","    loss at batch 0: 2.5143213272094727\n","    loss at batch 1: 2.98364520072937\n","    loss at batch 2: 2.3298768997192383\n","    loss at batch 3: 3.4443411827087402\n","    loss at batch 4: 4.160412311553955\n","epoch time 5.6645612716674805\n","Beginning training epoch 93\n","    loss at batch 0: 2.5168395042419434\n","    loss at batch 1: 2.790195941925049\n","    loss at batch 2: 3.711493968963623\n","    loss at batch 3: 3.255274534225464\n","    loss at batch 4: 3.0287249088287354\n","epoch time 5.788576126098633\n","Beginning training epoch 94\n","    loss at batch 0: 3.870500087738037\n","    loss at batch 1: 2.6678483486175537\n","    loss at batch 2: 3.5523247718811035\n","    loss at batch 3: 2.3618853092193604\n","    loss at batch 4: 3.0875508785247803\n","epoch time 5.8005290031433105\n","Beginning training epoch 95\n","    loss at batch 0: 3.6739132404327393\n","    loss at batch 1: 3.138343334197998\n","    loss at batch 2: 3.9334142208099365\n","    loss at batch 3: 2.441755533218384\n","    loss at batch 4: 3.8134870529174805\n","epoch time 5.915855884552002\n","\n","    Validation loss at epoch 95: 3.589951515197754\n","\n","Beginning training epoch 96\n","    loss at batch 0: 2.809990406036377\n","    loss at batch 1: 2.8000433444976807\n","    loss at batch 2: 2.544780731201172\n","    loss at batch 3: 3.667548179626465\n","    loss at batch 4: 2.6070010662078857\n","epoch time 5.806480407714844\n","Beginning training epoch 97\n","    loss at batch 0: 3.1876823902130127\n","    loss at batch 1: 2.4922285079956055\n","    loss at batch 2: 2.523681640625\n","    loss at batch 3: 3.262059211730957\n","    loss at batch 4: 1.8186750411987305\n","epoch time 5.775847434997559\n","Beginning training epoch 98\n","    loss at batch 0: 3.523514986038208\n","    loss at batch 1: 2.6280412673950195\n","    loss at batch 2: 2.6478636264801025\n","    loss at batch 3: 3.1522088050842285\n","    loss at batch 4: 4.240377426147461\n","epoch time 5.844620943069458\n","Beginning training epoch 99\n","    loss at batch 0: 2.8611323833465576\n","    loss at batch 1: 3.460129499435425\n","    loss at batch 2: 3.164954423904419\n","    loss at batch 3: 2.5184245109558105\n","    loss at batch 4: 2.861574172973633\n","epoch time 5.804278373718262\n","Beginning training epoch 100\n","    loss at batch 0: 3.4216065406799316\n","    loss at batch 1: 2.4534149169921875\n","    loss at batch 2: 2.9541916847229004\n","    loss at batch 3: 2.706413745880127\n","    loss at batch 4: 4.110146522521973\n","epoch time 5.874678373336792\n","\n","    Validation loss at epoch 100: 3.292198657989502\n","\n","Beginning training epoch 101\n","    loss at batch 0: 3.3065967559814453\n","    loss at batch 1: 2.8102221488952637\n","    loss at batch 2: 2.721144676208496\n","    loss at batch 3: 4.57009220123291\n","    loss at batch 4: 2.3653862476348877\n","epoch time 5.871046304702759\n","Beginning training epoch 102\n","    loss at batch 0: 3.6844663619995117\n","    loss at batch 1: 3.031008720397949\n","    loss at batch 2: 2.9957501888275146\n","    loss at batch 3: 2.821403980255127\n","    loss at batch 4: 3.5631515979766846\n","epoch time 5.861100912094116\n","Beginning training epoch 103\n","    loss at batch 0: 4.164552688598633\n","    loss at batch 1: 3.8855607509613037\n","    loss at batch 2: 2.4597482681274414\n","    loss at batch 3: 3.3993170261383057\n","    loss at batch 4: 2.4841701984405518\n","epoch time 5.84245491027832\n","Beginning training epoch 104\n","    loss at batch 0: 4.017159461975098\n","    loss at batch 1: 3.2217798233032227\n","    loss at batch 2: 3.0143837928771973\n","    loss at batch 3: 4.303938388824463\n","    loss at batch 4: 2.417848587036133\n","epoch time 5.816809892654419\n","Beginning training epoch 105\n","    loss at batch 0: 2.3962931632995605\n","    loss at batch 1: 2.762664556503296\n","    loss at batch 2: 3.683171510696411\n","    loss at batch 3: 2.7716593742370605\n","    loss at batch 4: 4.297749042510986\n","epoch time 5.833237171173096\n","\n","    Validation loss at epoch 105: 3.719363212585449\n","\n","Beginning training epoch 106\n","    loss at batch 0: 3.1812148094177246\n","    loss at batch 1: 3.60636043548584\n","    loss at batch 2: 2.739304542541504\n","    loss at batch 3: 2.726323127746582\n","    loss at batch 4: 3.9376699924468994\n","epoch time 5.781040906906128\n","Beginning training epoch 107\n","    loss at batch 0: 3.3789432048797607\n","    loss at batch 1: 2.2173025608062744\n","    loss at batch 2: 2.3154585361480713\n","    loss at batch 3: 2.8771555423736572\n","    loss at batch 4: 2.3848633766174316\n","epoch time 5.81580924987793\n","Beginning training epoch 108\n","    loss at batch 0: 3.1466829776763916\n","    loss at batch 1: 2.5378577709198\n","    loss at batch 2: 3.442739486694336\n","    loss at batch 3: 2.4790055751800537\n","    loss at batch 4: 3.1534183025360107\n","epoch time 5.839443683624268\n","Beginning training epoch 109\n","    loss at batch 0: 2.8805387020111084\n","    loss at batch 1: 3.4444220066070557\n","    loss at batch 2: 2.9928600788116455\n","    loss at batch 3: 2.1241884231567383\n","    loss at batch 4: 5.594796657562256\n","epoch time 5.820093154907227\n","Beginning training epoch 110\n","    loss at batch 0: 2.835556983947754\n","    loss at batch 1: 2.9683845043182373\n","    loss at batch 2: 2.7219152450561523\n","    loss at batch 3: 2.3949670791625977\n","    loss at batch 4: 2.844982385635376\n","epoch time 5.800815582275391\n","\n","    Validation loss at epoch 110: 3.2077865600585938\n","\n","Beginning training epoch 111\n","    loss at batch 0: 3.17311954498291\n","    loss at batch 1: 2.288641929626465\n","    loss at batch 2: 3.321063280105591\n","    loss at batch 3: 3.257805824279785\n","    loss at batch 4: 3.673445701599121\n","epoch time 5.825738906860352\n","Beginning training epoch 112\n","    loss at batch 0: 3.120375156402588\n","    loss at batch 1: 3.763251543045044\n","    loss at batch 2: 2.4933724403381348\n","    loss at batch 3: 3.5201852321624756\n","    loss at batch 4: 4.584051132202148\n","epoch time 5.916531324386597\n","Beginning training epoch 113\n","    loss at batch 0: 2.99918270111084\n","    loss at batch 1: 3.0500614643096924\n","    loss at batch 2: 2.4547033309936523\n","    loss at batch 3: 3.3230981826782227\n","    loss at batch 4: 3.222536087036133\n","epoch time 5.820665597915649\n","Beginning training epoch 114\n","    loss at batch 0: 3.0708718299865723\n","    loss at batch 1: 3.321863889694214\n","    loss at batch 2: 2.737910747528076\n","    loss at batch 3: 2.501904010772705\n","    loss at batch 4: 2.7787370681762695\n","epoch time 5.816943883895874\n","Beginning training epoch 115\n","    loss at batch 0: 2.6126482486724854\n","    loss at batch 1: 2.684539318084717\n","    loss at batch 2: 3.4748623371124268\n","    loss at batch 3: 2.965517997741699\n","    loss at batch 4: 3.3425698280334473\n","epoch time 5.739813566207886\n","\n","    Validation loss at epoch 115: 4.210056781768799\n","\n","Beginning training epoch 116\n","    loss at batch 0: 2.65763258934021\n","    loss at batch 1: 2.885920524597168\n","    loss at batch 2: 2.128427743911743\n","    loss at batch 3: 4.227265357971191\n","    loss at batch 4: 3.4205093383789062\n","epoch time 5.926302433013916\n","Beginning training epoch 117\n","    loss at batch 0: 2.789832830429077\n","    loss at batch 1: 1.9139372110366821\n","    loss at batch 2: 2.9140496253967285\n","    loss at batch 3: 3.427604913711548\n","    loss at batch 4: 2.4457855224609375\n","epoch time 5.909651041030884\n","Beginning training epoch 118\n","    loss at batch 0: 3.5721547603607178\n","    loss at batch 1: 2.490056276321411\n","    loss at batch 2: 3.534724235534668\n","    loss at batch 3: 3.0411596298217773\n","    loss at batch 4: 2.8085122108459473\n","epoch time 5.801855802536011\n","Beginning training epoch 119\n","    loss at batch 0: 2.4473745822906494\n","    loss at batch 1: 3.2290115356445312\n","    loss at batch 2: 3.2391269207000732\n","    loss at batch 3: 2.865318536758423\n","    loss at batch 4: 3.3205161094665527\n","epoch time 5.9353156089782715\n","Beginning training epoch 120\n","    loss at batch 0: 4.203980922698975\n","    loss at batch 1: 2.4961447715759277\n","    loss at batch 2: 2.769251823425293\n","    loss at batch 3: 2.60158371925354\n","    loss at batch 4: 2.1726572513580322\n","epoch time 5.849977254867554\n","\n","    Validation loss at epoch 120: 3.136387825012207\n","\n","Beginning training epoch 121\n","    loss at batch 0: 2.7544493675231934\n","    loss at batch 1: 3.4141950607299805\n","    loss at batch 2: 2.839939594268799\n","    loss at batch 3: 2.919532299041748\n","    loss at batch 4: 2.809394598007202\n","epoch time 5.883459091186523\n","Beginning training epoch 122\n","    loss at batch 0: 3.4544825553894043\n","    loss at batch 1: 2.776265859603882\n","    loss at batch 2: 3.23714542388916\n","    loss at batch 3: 2.5840775966644287\n","    loss at batch 4: 2.0052826404571533\n","epoch time 5.885484218597412\n","Beginning training epoch 123\n","    loss at batch 0: 3.0457024574279785\n","    loss at batch 1: 3.0351741313934326\n","    loss at batch 2: 2.8405025005340576\n","    loss at batch 3: 2.838686227798462\n","    loss at batch 4: 4.12104606628418\n","epoch time 5.767802476882935\n","Beginning training epoch 124\n","    loss at batch 0: 2.644599676132202\n","    loss at batch 1: 2.5337400436401367\n","    loss at batch 2: 4.0116705894470215\n","    loss at batch 3: 2.7989768981933594\n","    loss at batch 4: 3.8282270431518555\n","epoch time 5.712484121322632\n","Beginning training epoch 125\n","    loss at batch 0: 2.7305874824523926\n","    loss at batch 1: 2.7743186950683594\n","    loss at batch 2: 2.989506483078003\n","    loss at batch 3: 2.7923953533172607\n","    loss at batch 4: 4.379215240478516\n","epoch time 5.835522413253784\n","\n","    Validation loss at epoch 125: 3.223606824874878\n","\n","Beginning training epoch 126\n","    loss at batch 0: 3.634474515914917\n","    loss at batch 1: 2.2645437717437744\n","    loss at batch 2: 2.672102212905884\n","    loss at batch 3: 4.039434432983398\n","    loss at batch 4: 2.864689826965332\n","epoch time 5.993539571762085\n","Beginning training epoch 127\n","    loss at batch 0: 2.570024251937866\n","    loss at batch 1: 2.123116970062256\n","    loss at batch 2: 4.1519060134887695\n","    loss at batch 3: 3.0692310333251953\n","    loss at batch 4: 2.810408353805542\n","epoch time 5.948139667510986\n","Beginning training epoch 128\n","    loss at batch 0: 3.5809524059295654\n","    loss at batch 1: 4.345604419708252\n","    loss at batch 2: 2.6334421634674072\n","    loss at batch 3: 2.3452036380767822\n","    loss at batch 4: 2.456026077270508\n","epoch time 5.943257570266724\n","Beginning training epoch 129\n","    loss at batch 0: 2.3774831295013428\n","    loss at batch 1: 2.7744147777557373\n","    loss at batch 2: 2.52417254447937\n","    loss at batch 3: 2.5791499614715576\n","    loss at batch 4: 2.4340057373046875\n","epoch time 5.912235498428345\n","Beginning training epoch 130\n","    loss at batch 0: 2.489187240600586\n","    loss at batch 1: 2.721302032470703\n","    loss at batch 2: 2.446363925933838\n","    loss at batch 3: 2.6958847045898438\n","    loss at batch 4: 3.164921283721924\n","epoch time 5.834806442260742\n","\n","    Validation loss at epoch 130: 2.9782893657684326\n","\n","Beginning training epoch 131\n","    loss at batch 0: 2.7849175930023193\n","    loss at batch 1: 3.8685407638549805\n","    loss at batch 2: 2.4819860458374023\n","    loss at batch 3: 2.3617050647735596\n","    loss at batch 4: 4.594114780426025\n","epoch time 5.907480955123901\n","Beginning training epoch 132\n","    loss at batch 0: 2.7759485244750977\n","    loss at batch 1: 3.507082939147949\n","    loss at batch 2: 2.911250591278076\n","    loss at batch 3: 2.62458872795105\n","    loss at batch 4: 3.9931318759918213\n","epoch time 5.875355243682861\n","Beginning training epoch 133\n","    loss at batch 0: 2.713766098022461\n","    loss at batch 1: 2.7995848655700684\n","    loss at batch 2: 2.8173093795776367\n","    loss at batch 3: 2.512390375137329\n","    loss at batch 4: 3.4450459480285645\n","epoch time 5.7617480754852295\n","Beginning training epoch 134\n","    loss at batch 0: 2.4935336112976074\n","    loss at batch 1: 2.4996771812438965\n","    loss at batch 2: 2.6151559352874756\n","    loss at batch 3: 2.6878156661987305\n","    loss at batch 4: 3.9537909030914307\n","epoch time 5.857833385467529\n","Beginning training epoch 135\n","    loss at batch 0: 2.6378118991851807\n","    loss at batch 1: 2.7800118923187256\n","    loss at batch 2: 2.2916603088378906\n","    loss at batch 3: 3.303271532058716\n","    loss at batch 4: 1.4429000616073608\n","epoch time 5.911010026931763\n","\n","    Validation loss at epoch 135: 2.2776074409484863\n","\n","Beginning training epoch 136\n","    loss at batch 0: 2.9443650245666504\n","    loss at batch 1: 2.1834259033203125\n","    loss at batch 2: 2.5441501140594482\n","    loss at batch 3: 2.2912445068359375\n","    loss at batch 4: 2.7420597076416016\n","epoch time 5.90939998626709\n","Beginning training epoch 137\n","    loss at batch 0: 3.9364335536956787\n","    loss at batch 1: 2.1548149585723877\n","    loss at batch 2: 3.1869001388549805\n","    loss at batch 3: 2.666049003601074\n","    loss at batch 4: 2.6930477619171143\n","epoch time 5.848849296569824\n","Beginning training epoch 138\n","    loss at batch 0: 2.3880372047424316\n","    loss at batch 1: 2.3178915977478027\n","    loss at batch 2: 2.2465028762817383\n","    loss at batch 3: 3.0424790382385254\n","    loss at batch 4: 4.208101749420166\n","epoch time 5.5366716384887695\n","Beginning training epoch 139\n","    loss at batch 0: 2.7764482498168945\n","    loss at batch 1: 3.0391170978546143\n","    loss at batch 2: 2.6798572540283203\n","    loss at batch 3: 3.7085044384002686\n","    loss at batch 4: 2.751052141189575\n","epoch time 5.8167808055877686\n","Beginning training epoch 140\n","    loss at batch 0: 2.2676126956939697\n","    loss at batch 1: 3.046100616455078\n","    loss at batch 2: 2.3734169006347656\n","    loss at batch 3: 2.8466875553131104\n","    loss at batch 4: 4.396916389465332\n","epoch time 5.844565153121948\n","\n","    Validation loss at epoch 140: 2.661677598953247\n","\n","Beginning training epoch 141\n","    loss at batch 0: 2.4248762130737305\n","    loss at batch 1: 2.9354496002197266\n","    loss at batch 2: 2.862797975540161\n","    loss at batch 3: 2.8871397972106934\n","    loss at batch 4: 2.713935136795044\n","epoch time 5.814842939376831\n","Beginning training epoch 142\n","    loss at batch 0: 2.9182047843933105\n","    loss at batch 1: 2.6746294498443604\n","    loss at batch 2: 2.5675547122955322\n","    loss at batch 3: 2.592872142791748\n","    loss at batch 4: 4.33823823928833\n","epoch time 5.810864448547363\n","Beginning training epoch 143\n","    loss at batch 0: 3.5078177452087402\n","    loss at batch 1: 3.0017147064208984\n","    loss at batch 2: 2.843641757965088\n","    loss at batch 3: 2.7396433353424072\n","    loss at batch 4: 2.833190441131592\n","epoch time 5.84530234336853\n","Beginning training epoch 144\n","    loss at batch 0: 2.6324281692504883\n","    loss at batch 1: 2.3841946125030518\n","    loss at batch 2: 2.251114845275879\n","    loss at batch 3: 2.899859666824341\n","    loss at batch 4: 3.282456159591675\n","epoch time 5.763957500457764\n","Beginning training epoch 145\n","    loss at batch 0: 2.8557493686676025\n","    loss at batch 1: 3.0204360485076904\n","    loss at batch 2: 2.6645143032073975\n","    loss at batch 3: 2.594011068344116\n","    loss at batch 4: 3.177839517593384\n","epoch time 5.8837971687316895\n","\n","    Validation loss at epoch 145: 2.8322014808654785\n","\n","Beginning training epoch 146\n","    loss at batch 0: 2.78375506401062\n","    loss at batch 1: 2.8259918689727783\n","    loss at batch 2: 2.0813987255096436\n","    loss at batch 3: 3.606923818588257\n","    loss at batch 4: 3.8731601238250732\n","epoch time 5.874002933502197\n","Beginning training epoch 147\n","    loss at batch 0: 2.778702974319458\n","    loss at batch 1: 2.4413013458251953\n","    loss at batch 2: 2.7308976650238037\n","    loss at batch 3: 2.811490058898926\n","    loss at batch 4: 2.0259573459625244\n","epoch time 5.791222810745239\n","Beginning training epoch 148\n","    loss at batch 0: 2.697964668273926\n","    loss at batch 1: 3.7426247596740723\n","    loss at batch 2: 2.75294828414917\n","    loss at batch 3: 3.7026422023773193\n","    loss at batch 4: 2.50901198387146\n","epoch time 5.838684558868408\n","Beginning training epoch 149\n","    loss at batch 0: 2.1205856800079346\n","    loss at batch 1: 3.5222175121307373\n","    loss at batch 2: 2.751948118209839\n","    loss at batch 3: 2.982816457748413\n","    loss at batch 4: 2.7902348041534424\n","epoch time 5.797290563583374\n","Beginning training epoch 150\n","    loss at batch 0: 3.312366485595703\n","    loss at batch 1: 3.317986488342285\n","    loss at batch 2: 3.546884775161743\n","    loss at batch 3: 3.1637651920318604\n","    loss at batch 4: 2.3277969360351562\n","epoch time 5.8891050815582275\n","\n","    Validation loss at epoch 150: 4.8784637451171875\n","\n","Beginning training epoch 151\n","    loss at batch 0: 3.092578887939453\n","    loss at batch 1: 2.7751169204711914\n","    loss at batch 2: 3.5603458881378174\n","    loss at batch 3: 2.7950146198272705\n","    loss at batch 4: 3.4631106853485107\n","epoch time 5.964258670806885\n","Beginning training epoch 152\n","    loss at batch 0: 3.198970317840576\n","    loss at batch 1: 3.2201223373413086\n","    loss at batch 2: 2.8948941230773926\n","    loss at batch 3: 3.4701712131500244\n","    loss at batch 4: 1.799286127090454\n","epoch time 5.8336098194122314\n","Beginning training epoch 153\n","    loss at batch 0: 3.036283493041992\n","    loss at batch 1: 2.3099265098571777\n","    loss at batch 2: 2.7853198051452637\n","    loss at batch 3: 2.6817898750305176\n","    loss at batch 4: 3.6365582942962646\n","epoch time 5.910669803619385\n","Beginning training epoch 154\n","    loss at batch 0: 2.2971887588500977\n","    loss at batch 1: 2.510549783706665\n","    loss at batch 2: 3.613398790359497\n","    loss at batch 3: 3.0405771732330322\n","    loss at batch 4: 2.8046040534973145\n","epoch time 5.888818025588989\n","Beginning training epoch 155\n","    loss at batch 0: 3.2271788120269775\n","    loss at batch 1: 2.6087474822998047\n","    loss at batch 2: 2.3001487255096436\n","    loss at batch 3: 2.99472713470459\n","    loss at batch 4: 3.8196165561676025\n","epoch time 5.84571647644043\n","\n","    Validation loss at epoch 155: 3.387092351913452\n","\n","Beginning training epoch 156\n","    loss at batch 0: 2.82491397857666\n","    loss at batch 1: 2.9882113933563232\n","    loss at batch 2: 2.6331143379211426\n","    loss at batch 3: 3.054361343383789\n","    loss at batch 4: 2.5748960971832275\n","epoch time 5.919934272766113\n","Beginning training epoch 157\n","    loss at batch 0: 3.4162678718566895\n","    loss at batch 1: 2.1563894748687744\n","    loss at batch 2: 2.7059500217437744\n","    loss at batch 3: 3.0200395584106445\n","    loss at batch 4: 1.8932812213897705\n","epoch time 5.649622440338135\n","Beginning training epoch 158\n","    loss at batch 0: 2.577521800994873\n","    loss at batch 1: 2.691645622253418\n","    loss at batch 2: 2.6718599796295166\n","    loss at batch 3: 2.6790714263916016\n","    loss at batch 4: 2.2409517765045166\n","epoch time 5.751668453216553\n","Beginning training epoch 159\n","    loss at batch 0: 2.042311906814575\n","    loss at batch 1: 2.711956739425659\n","    loss at batch 2: 3.055166482925415\n","    loss at batch 3: 2.564584970474243\n","    loss at batch 4: 2.594648838043213\n","epoch time 5.853133678436279\n","Beginning training epoch 160\n","    loss at batch 0: 2.756871461868286\n","    loss at batch 1: 2.7783265113830566\n","    loss at batch 2: 2.2128162384033203\n","    loss at batch 3: 2.4017646312713623\n","    loss at batch 4: 1.2340906858444214\n","epoch time 5.8601038455963135\n","\n","    Validation loss at epoch 160: 2.7326273918151855\n","\n","Beginning training epoch 161\n","    loss at batch 0: 3.2071094512939453\n","    loss at batch 1: 2.2878811359405518\n","    loss at batch 2: 3.253840446472168\n","    loss at batch 3: 2.4658055305480957\n","    loss at batch 4: 2.7785751819610596\n","epoch time 5.757771015167236\n","Beginning training epoch 162\n","    loss at batch 0: 2.6590867042541504\n","    loss at batch 1: 2.9754650592803955\n","    loss at batch 2: 2.6818642616271973\n","    loss at batch 3: 2.879300594329834\n","    loss at batch 4: 3.065640449523926\n","epoch time 5.818460464477539\n","Beginning training epoch 163\n","    loss at batch 0: 2.741597890853882\n","    loss at batch 1: 2.396542549133301\n","    loss at batch 2: 2.45927357673645\n","    loss at batch 3: 2.2974729537963867\n","    loss at batch 4: 5.53629732131958\n","epoch time 5.781581401824951\n","Beginning training epoch 164\n","    loss at batch 0: 2.795321464538574\n","    loss at batch 1: 2.894345283508301\n","    loss at batch 2: 2.6775670051574707\n","    loss at batch 3: 2.930807113647461\n","    loss at batch 4: 2.0884957313537598\n","epoch time 5.817155361175537\n","Beginning training epoch 165\n","    loss at batch 0: 2.7540535926818848\n","    loss at batch 1: 2.9270246028900146\n","    loss at batch 2: 2.374727725982666\n","    loss at batch 3: 3.013460397720337\n","    loss at batch 4: 2.0299155712127686\n","epoch time 5.769311904907227\n","\n","    Validation loss at epoch 165: 3.0388240814208984\n","\n","Beginning training epoch 166\n","    loss at batch 0: 3.274521827697754\n","    loss at batch 1: 2.4966747760772705\n","    loss at batch 2: 3.2816269397735596\n","    loss at batch 3: 2.5407092571258545\n","    loss at batch 4: 4.368478775024414\n","epoch time 5.798353910446167\n","Beginning training epoch 167\n","    loss at batch 0: 2.883098602294922\n","    loss at batch 1: 2.7506933212280273\n","    loss at batch 2: 2.7387640476226807\n","    loss at batch 3: 2.573181629180908\n","    loss at batch 4: 1.210762858390808\n","epoch time 5.77701735496521\n","Beginning training epoch 168\n","    loss at batch 0: 2.8907580375671387\n","    loss at batch 1: 2.4675533771514893\n","    loss at batch 2: 3.373084306716919\n","    loss at batch 3: 2.6556520462036133\n","    loss at batch 4: 2.0020558834075928\n","epoch time 5.803046226501465\n","Beginning training epoch 169\n","    loss at batch 0: 2.0145201683044434\n","    loss at batch 1: 3.823058605194092\n","    loss at batch 2: 2.3094911575317383\n","    loss at batch 3: 2.9173996448516846\n","    loss at batch 4: 3.2898623943328857\n","epoch time 5.768221855163574\n","Beginning training epoch 170\n","    loss at batch 0: 2.291531801223755\n","    loss at batch 1: 2.3937387466430664\n","    loss at batch 2: 2.6587140560150146\n","    loss at batch 3: 2.2632741928100586\n","    loss at batch 4: 2.771679639816284\n","epoch time 5.78584885597229\n","\n","    Validation loss at epoch 170: 3.082493782043457\n","\n","Beginning training epoch 171\n","    loss at batch 0: 2.585951328277588\n","    loss at batch 1: 2.4298276901245117\n","    loss at batch 2: 2.2061657905578613\n","    loss at batch 3: 3.3546555042266846\n","    loss at batch 4: 2.746114730834961\n","epoch time 5.851810455322266\n","Beginning training epoch 172\n","    loss at batch 0: 2.7902865409851074\n","    loss at batch 1: 2.1905105113983154\n","    loss at batch 2: 2.552738904953003\n","    loss at batch 3: 2.460555076599121\n","    loss at batch 4: 1.9874799251556396\n","epoch time 5.793178558349609\n","Beginning training epoch 173\n","    loss at batch 0: 2.128448009490967\n","    loss at batch 1: 2.720038414001465\n","    loss at batch 2: 2.340491771697998\n","    loss at batch 3: 2.598594903945923\n","    loss at batch 4: 3.452810525894165\n","epoch time 5.551981449127197\n","Beginning training epoch 174\n","    loss at batch 0: 2.5769765377044678\n","    loss at batch 1: 2.1639039516448975\n","    loss at batch 2: 2.5714282989501953\n","    loss at batch 3: 2.888672351837158\n","    loss at batch 4: 2.669902801513672\n","epoch time 5.7956321239471436\n","Beginning training epoch 175\n","    loss at batch 0: 2.7136943340301514\n","    loss at batch 1: 2.739220380783081\n","    loss at batch 2: 2.264584541320801\n","    loss at batch 3: 2.858433961868286\n","    loss at batch 4: 3.393827438354492\n","epoch time 5.860147476196289\n","\n","    Validation loss at epoch 175: 2.6191015243530273\n","\n","Beginning training epoch 176\n","    loss at batch 0: 2.5869576930999756\n","    loss at batch 1: 2.6597037315368652\n","    loss at batch 2: 2.5733180046081543\n","    loss at batch 3: 2.6391959190368652\n","    loss at batch 4: 2.9292941093444824\n","epoch time 5.853081703186035\n","Beginning training epoch 177\n","    loss at batch 0: 2.0346591472625732\n","    loss at batch 1: 2.3528237342834473\n","    loss at batch 2: 2.386301040649414\n","    loss at batch 3: 2.751095771789551\n","    loss at batch 4: 1.7367970943450928\n","epoch time 5.904221534729004\n","Beginning training epoch 178\n","    loss at batch 0: 2.889098882675171\n","    loss at batch 1: 1.9895026683807373\n","    loss at batch 2: 2.22165584564209\n","    loss at batch 3: 2.371542453765869\n","    loss at batch 4: 2.332563877105713\n","epoch time 5.790585279464722\n","Beginning training epoch 179\n","    loss at batch 0: 3.041217803955078\n","    loss at batch 1: 2.3578288555145264\n","    loss at batch 2: 1.932481288909912\n","    loss at batch 3: 2.2610676288604736\n","    loss at batch 4: 3.7043631076812744\n","epoch time 5.785206079483032\n","Beginning training epoch 180\n","    loss at batch 0: 2.225090503692627\n","    loss at batch 1: 2.4204087257385254\n","    loss at batch 2: 3.1815927028656006\n","    loss at batch 3: 2.1149697303771973\n","    loss at batch 4: 1.6731497049331665\n","epoch time 5.840924501419067\n","\n","    Validation loss at epoch 180: 3.1460118293762207\n","\n","Beginning training epoch 181\n","    loss at batch 0: 2.6994166374206543\n","    loss at batch 1: 2.38071870803833\n","    loss at batch 2: 2.4750943183898926\n","    loss at batch 3: 2.4214165210723877\n","    loss at batch 4: 3.318665027618408\n","epoch time 5.920013904571533\n","Beginning training epoch 182\n","    loss at batch 0: 2.087235450744629\n","    loss at batch 1: 2.916592597961426\n","    loss at batch 2: 2.026442289352417\n","    loss at batch 3: 2.9904985427856445\n","    loss at batch 4: 2.499680757522583\n","epoch time 5.916090965270996\n","Beginning training epoch 183\n","    loss at batch 0: 2.332812786102295\n","    loss at batch 1: 2.9542253017425537\n","    loss at batch 2: 4.252460479736328\n","    loss at batch 3: 2.423973560333252\n","    loss at batch 4: 3.5636019706726074\n","epoch time 5.856435537338257\n","Beginning training epoch 184\n","    loss at batch 0: 3.511096477508545\n","    loss at batch 1: 2.3729360103607178\n","    loss at batch 2: 2.916559934616089\n","    loss at batch 3: 2.9716391563415527\n","    loss at batch 4: 4.628828048706055\n","epoch time 5.83638072013855\n","Beginning training epoch 185\n","    loss at batch 0: 2.9607832431793213\n","    loss at batch 1: 2.591750383377075\n","    loss at batch 2: 2.354456663131714\n","    loss at batch 3: 2.2498459815979004\n","    loss at batch 4: 2.650395393371582\n","epoch time 5.646698951721191\n","\n","    Validation loss at epoch 185: 2.9920220375061035\n","\n","Beginning training epoch 186\n","    loss at batch 0: 2.8034002780914307\n","    loss at batch 1: 2.657407760620117\n","    loss at batch 2: 3.001826763153076\n","    loss at batch 3: 2.3776447772979736\n","    loss at batch 4: 1.7599838972091675\n","epoch time 5.885486841201782\n","Beginning training epoch 187\n","    loss at batch 0: 2.51047945022583\n","    loss at batch 1: 2.1396100521087646\n","    loss at batch 2: 2.516570806503296\n","    loss at batch 3: 2.7860372066497803\n","    loss at batch 4: 1.789754033088684\n","epoch time 5.7606589794158936\n","Beginning training epoch 188\n","    loss at batch 0: 2.3234188556671143\n","    loss at batch 1: 2.8788061141967773\n","    loss at batch 2: 2.7168498039245605\n","    loss at batch 3: 2.323474407196045\n","    loss at batch 4: 2.8200531005859375\n","epoch time 5.842932224273682\n","Beginning training epoch 189\n","    loss at batch 0: 2.344863176345825\n","    loss at batch 1: 3.2268357276916504\n","    loss at batch 2: 2.3239452838897705\n","    loss at batch 3: 2.631101608276367\n","    loss at batch 4: 2.0907013416290283\n","epoch time 5.894665718078613\n","Beginning training epoch 190\n","    loss at batch 0: 3.5433552265167236\n","    loss at batch 1: 2.1344568729400635\n","    loss at batch 2: 2.927685260772705\n","    loss at batch 3: 2.8383982181549072\n","    loss at batch 4: 3.8673956394195557\n","epoch time 5.752453565597534\n","\n","    Validation loss at epoch 190: 2.608936309814453\n","\n","Beginning training epoch 191\n","    loss at batch 0: 2.4796626567840576\n","    loss at batch 1: 2.4789302349090576\n","    loss at batch 2: 2.060192108154297\n","    loss at batch 3: 2.671957015991211\n","    loss at batch 4: 2.1691155433654785\n","epoch time 5.791011333465576\n","Beginning training epoch 192\n","    loss at batch 0: 3.1397345066070557\n","    loss at batch 1: 2.0970356464385986\n","    loss at batch 2: 2.8909363746643066\n","    loss at batch 3: 2.126136064529419\n","    loss at batch 4: 4.014193534851074\n","epoch time 5.888326644897461\n","Beginning training epoch 193\n","    loss at batch 0: 2.733975887298584\n","    loss at batch 1: 2.8834140300750732\n","    loss at batch 2: 2.2170050144195557\n","    loss at batch 3: 2.6524784564971924\n","    loss at batch 4: 1.9659231901168823\n","epoch time 5.892376184463501\n","Beginning training epoch 194\n","    loss at batch 0: 2.6351475715637207\n","    loss at batch 1: 2.246821403503418\n","    loss at batch 2: 2.53704571723938\n","    loss at batch 3: 2.9832215309143066\n","    loss at batch 4: 3.2311043739318848\n","epoch time 5.775128126144409\n","Beginning training epoch 195\n","    loss at batch 0: 1.9948136806488037\n","    loss at batch 1: 2.452345609664917\n","    loss at batch 2: 2.9499311447143555\n","    loss at batch 3: 2.8247270584106445\n","    loss at batch 4: 2.142275094985962\n","epoch time 5.834655523300171\n","\n","    Validation loss at epoch 195: 2.284874677658081\n","\n","Beginning training epoch 196\n","    loss at batch 0: 2.5508737564086914\n","    loss at batch 1: 2.0835354328155518\n","    loss at batch 2: 3.443699359893799\n","    loss at batch 3: 3.0429956912994385\n","    loss at batch 4: 2.8177924156188965\n","epoch time 5.7805023193359375\n","Beginning training epoch 197\n","    loss at batch 0: 2.5641186237335205\n","    loss at batch 1: 2.0629074573516846\n","    loss at batch 2: 2.213291645050049\n","    loss at batch 3: 2.2303242683410645\n","    loss at batch 4: 2.146768093109131\n","epoch time 5.667510032653809\n","Beginning training epoch 198\n","    loss at batch 0: 2.709038019180298\n","    loss at batch 1: 1.602839469909668\n","    loss at batch 2: 2.7328178882598877\n","    loss at batch 3: 2.139244556427002\n","    loss at batch 4: 2.161757230758667\n","epoch time 5.784397840499878\n","Beginning training epoch 199\n","    loss at batch 0: 2.600844383239746\n","    loss at batch 1: 2.6746816635131836\n","    loss at batch 2: 2.5866262912750244\n","    loss at batch 3: 2.602588176727295\n","    loss at batch 4: 1.9086016416549683\n","epoch time 5.780597686767578\n","Beginning training epoch 200\n","    loss at batch 0: 2.882946491241455\n","    loss at batch 1: 2.3398056030273438\n","    loss at batch 2: 3.915949821472168\n","    loss at batch 3: 1.9644687175750732\n","    loss at batch 4: 1.0138790607452393\n","epoch time 5.796536922454834\n","\n","    Validation loss at epoch 200: 2.458041191101074\n","\n","Beginning training epoch 201\n","    loss at batch 0: 2.513794422149658\n","    loss at batch 1: 2.5969977378845215\n","    loss at batch 2: 2.455810546875\n","    loss at batch 3: 2.3956475257873535\n","    loss at batch 4: 1.735977053642273\n","epoch time 5.890915393829346\n","Beginning training epoch 202\n","    loss at batch 0: 2.2359542846679688\n","    loss at batch 1: 2.4738097190856934\n","    loss at batch 2: 3.1689319610595703\n","    loss at batch 3: 1.9151089191436768\n","    loss at batch 4: 1.5911670923233032\n","epoch time 5.685238599777222\n","Beginning training epoch 203\n","    loss at batch 0: 2.3464367389678955\n","    loss at batch 1: 1.8350579738616943\n","    loss at batch 2: 3.4664645195007324\n","    loss at batch 3: 2.550372362136841\n","    loss at batch 4: 1.7666420936584473\n","epoch time 5.783945798873901\n","Beginning training epoch 204\n","    loss at batch 0: 2.478940963745117\n","    loss at batch 1: 2.097797393798828\n","    loss at batch 2: 2.7468905448913574\n","    loss at batch 3: 2.9751102924346924\n","    loss at batch 4: 2.542616605758667\n","epoch time 5.927865505218506\n","Beginning training epoch 205\n","    loss at batch 0: 2.298792839050293\n","    loss at batch 1: 3.2835657596588135\n","    loss at batch 2: 2.6643264293670654\n","    loss at batch 3: 2.0342814922332764\n","    loss at batch 4: 2.1816866397857666\n","epoch time 5.879810571670532\n","\n","    Validation loss at epoch 205: 2.2466485500335693\n","\n","Beginning training epoch 206\n","    loss at batch 0: 2.353358030319214\n","    loss at batch 1: 2.073033094406128\n","    loss at batch 2: 2.1762235164642334\n","    loss at batch 3: 2.1778786182403564\n","    loss at batch 4: 1.7230548858642578\n","epoch time 5.847143888473511\n","Beginning training epoch 207\n","    loss at batch 0: 2.675539016723633\n","    loss at batch 1: 2.1708626747131348\n","    loss at batch 2: 2.041836738586426\n","    loss at batch 3: 3.2403297424316406\n","    loss at batch 4: 1.8872218132019043\n","epoch time 5.707628488540649\n","Beginning training epoch 208\n","    loss at batch 0: 1.710404396057129\n","    loss at batch 1: 2.063586473464966\n","    loss at batch 2: 3.183887481689453\n","    loss at batch 3: 2.053436517715454\n","    loss at batch 4: 2.1500792503356934\n","epoch time 5.818577289581299\n","Beginning training epoch 209\n","    loss at batch 0: 1.6954419612884521\n","    loss at batch 1: 2.771423101425171\n","    loss at batch 2: 2.452847480773926\n","    loss at batch 3: 2.306220769882202\n","    loss at batch 4: 1.135664463043213\n","epoch time 5.7965052127838135\n","Beginning training epoch 210\n","    loss at batch 0: 2.9359893798828125\n","    loss at batch 1: 2.9642252922058105\n","    loss at batch 2: 1.8451619148254395\n","    loss at batch 3: 2.4198079109191895\n","    loss at batch 4: 1.8752789497375488\n","epoch time 5.8008952140808105\n","\n","    Validation loss at epoch 210: 2.2741031646728516\n","\n","Beginning training epoch 211\n","    loss at batch 0: 3.149568796157837\n","    loss at batch 1: 2.1171815395355225\n","    loss at batch 2: 2.3446052074432373\n","    loss at batch 3: 2.1411807537078857\n","    loss at batch 4: 1.6870614290237427\n","epoch time 5.848404407501221\n","Beginning training epoch 212\n","    loss at batch 0: 2.2430801391601562\n","    loss at batch 1: 2.155604124069214\n","    loss at batch 2: 2.759775400161743\n","    loss at batch 3: 2.7161476612091064\n","    loss at batch 4: 2.2455458641052246\n","epoch time 5.852246522903442\n","Beginning training epoch 213\n","    loss at batch 0: 1.981028437614441\n","    loss at batch 1: 2.374382495880127\n","    loss at batch 2: 2.2290008068084717\n","    loss at batch 3: 2.0388882160186768\n","    loss at batch 4: 6.711021423339844\n","epoch time 5.801734685897827\n","Beginning training epoch 214\n","    loss at batch 0: 2.5438737869262695\n","    loss at batch 1: 1.8905689716339111\n","    loss at batch 2: 2.2071056365966797\n","    loss at batch 3: 3.3843023777008057\n","    loss at batch 4: 1.881028175354004\n","epoch time 5.791544198989868\n","Beginning training epoch 215\n","    loss at batch 0: 2.340721607208252\n","    loss at batch 1: 1.971373200416565\n","    loss at batch 2: 2.688176393508911\n","    loss at batch 3: 2.3741023540496826\n","    loss at batch 4: 2.7708845138549805\n","epoch time 5.746243953704834\n","\n","    Validation loss at epoch 215: 2.582240581512451\n","\n","Beginning training epoch 216\n","    loss at batch 0: 2.4458742141723633\n","    loss at batch 1: 2.5951056480407715\n","    loss at batch 2: 2.3347620964050293\n","    loss at batch 3: 2.21709942817688\n","    loss at batch 4: 3.473111867904663\n","epoch time 5.918811321258545\n","Beginning training epoch 217\n","    loss at batch 0: 2.350888967514038\n","    loss at batch 1: 2.157688856124878\n","    loss at batch 2: 2.058231830596924\n","    loss at batch 3: 3.223722457885742\n","    loss at batch 4: 2.732487440109253\n","epoch time 5.751911401748657\n","Beginning training epoch 218\n","    loss at batch 0: 3.190434694290161\n","    loss at batch 1: 2.546220302581787\n","    loss at batch 2: 1.8895090818405151\n","    loss at batch 3: 2.1277780532836914\n","    loss at batch 4: 3.269580364227295\n","epoch time 5.737766265869141\n","Beginning training epoch 219\n","    loss at batch 0: 2.392545223236084\n","    loss at batch 1: 2.382997512817383\n","    loss at batch 2: 2.1677865982055664\n","    loss at batch 3: 2.22278094291687\n","    loss at batch 4: 2.675031900405884\n","epoch time 5.912903070449829\n","Beginning training epoch 220\n","    loss at batch 0: 3.0824410915374756\n","    loss at batch 1: 2.478175640106201\n","    loss at batch 2: 2.818424940109253\n","    loss at batch 3: 2.1922876834869385\n","    loss at batch 4: 3.1076526641845703\n","epoch time 5.837209701538086\n","\n","    Validation loss at epoch 220: 2.5974643230438232\n","\n","Beginning training epoch 221\n","    loss at batch 0: 2.4306280612945557\n","    loss at batch 1: 2.587661027908325\n","    loss at batch 2: 2.8948302268981934\n","    loss at batch 3: 2.4361050128936768\n","    loss at batch 4: 1.8657987117767334\n","epoch time 5.863062858581543\n","Beginning training epoch 222\n","    loss at batch 0: 2.8190481662750244\n","    loss at batch 1: 2.104497194290161\n","    loss at batch 2: 3.2202072143554688\n","    loss at batch 3: 2.3997015953063965\n","    loss at batch 4: 1.9532287120819092\n","epoch time 5.739766597747803\n","Beginning training epoch 223\n","    loss at batch 0: 2.183483123779297\n","    loss at batch 1: 1.8613170385360718\n","    loss at batch 2: 2.678377389907837\n","    loss at batch 3: 2.6465513706207275\n","    loss at batch 4: 3.4477503299713135\n","epoch time 5.740793466567993\n","Beginning training epoch 224\n","    loss at batch 0: 2.694366216659546\n","    loss at batch 1: 2.364096164703369\n","    loss at batch 2: 2.7302298545837402\n","    loss at batch 3: 2.39998197555542\n","    loss at batch 4: 2.6118927001953125\n","epoch time 5.838263511657715\n","Beginning training epoch 225\n","    loss at batch 0: 2.4576268196105957\n","    loss at batch 1: 1.9427521228790283\n","    loss at batch 2: 2.0737216472625732\n","    loss at batch 3: 2.676665782928467\n","    loss at batch 4: 2.3810343742370605\n","epoch time 5.795230388641357\n","\n","    Validation loss at epoch 225: 2.292668342590332\n","\n","Beginning training epoch 226\n","    loss at batch 0: 2.045612335205078\n","    loss at batch 1: 2.0687592029571533\n","    loss at batch 2: 2.1813437938690186\n","    loss at batch 3: 2.079817771911621\n","    loss at batch 4: 4.211219787597656\n","epoch time 5.808760643005371\n","Beginning training epoch 227\n","    loss at batch 0: 2.000459909439087\n","    loss at batch 1: 2.227283239364624\n","    loss at batch 2: 1.8297373056411743\n","    loss at batch 3: 2.70371150970459\n","    loss at batch 4: 2.900397300720215\n","epoch time 5.842546463012695\n","Beginning training epoch 228\n","    loss at batch 0: 1.9760003089904785\n","    loss at batch 1: 2.4200923442840576\n","    loss at batch 2: 1.9135723114013672\n","    loss at batch 3: 2.0698013305664062\n","    loss at batch 4: 2.0576961040496826\n","epoch time 5.77114462852478\n","Beginning training epoch 229\n","    loss at batch 0: 2.6691439151763916\n","    loss at batch 1: 2.906846284866333\n","    loss at batch 2: 2.6902174949645996\n","    loss at batch 3: 2.1784496307373047\n","    loss at batch 4: 3.8818960189819336\n","epoch time 5.813896179199219\n","Beginning training epoch 230\n","    loss at batch 0: 2.6795601844787598\n","    loss at batch 1: 2.2833259105682373\n","    loss at batch 2: 2.76678204536438\n","    loss at batch 3: 2.551845073699951\n","    loss at batch 4: 3.4074082374572754\n","epoch time 5.758799314498901\n","\n","    Validation loss at epoch 230: 2.6846771240234375\n","\n","Beginning training epoch 231\n","    loss at batch 0: 1.9612163305282593\n","    loss at batch 1: 2.31070613861084\n","    loss at batch 2: 2.1295201778411865\n","    loss at batch 3: 2.661797285079956\n","    loss at batch 4: 2.4141764640808105\n","epoch time 5.823870897293091\n","Beginning training epoch 232\n","    loss at batch 0: 2.1674251556396484\n","    loss at batch 1: 2.2566163539886475\n","    loss at batch 2: 2.2689855098724365\n","    loss at batch 3: 2.4134559631347656\n","    loss at batch 4: 2.987236738204956\n","epoch time 5.802659511566162\n","Beginning training epoch 233\n","    loss at batch 0: 2.5058789253234863\n","    loss at batch 1: 2.728787660598755\n","    loss at batch 2: 2.25546932220459\n","    loss at batch 3: 2.091224193572998\n","    loss at batch 4: 2.260939359664917\n","epoch time 5.800073862075806\n","Beginning training epoch 234\n","    loss at batch 0: 2.1199116706848145\n","    loss at batch 1: 1.7686177492141724\n","    loss at batch 2: 2.1375229358673096\n","    loss at batch 3: 2.361894369125366\n","    loss at batch 4: 2.497164726257324\n","epoch time 5.8222620487213135\n","Beginning training epoch 235\n","    loss at batch 0: 2.197141647338867\n","    loss at batch 1: 2.1016976833343506\n","    loss at batch 2: 2.599440813064575\n","    loss at batch 3: 2.3835456371307373\n","    loss at batch 4: 3.136392116546631\n","epoch time 5.787723064422607\n","\n","    Validation loss at epoch 235: 2.371626615524292\n","\n","Beginning training epoch 236\n","    loss at batch 0: 2.3956451416015625\n","    loss at batch 1: 2.2329416275024414\n","    loss at batch 2: 2.1139252185821533\n","    loss at batch 3: 3.011831521987915\n","    loss at batch 4: 2.2021749019622803\n","epoch time 5.7679362297058105\n","Beginning training epoch 237\n","    loss at batch 0: 3.0909366607666016\n","    loss at batch 1: 2.443650245666504\n","    loss at batch 2: 2.4756252765655518\n","    loss at batch 3: 1.9615871906280518\n","    loss at batch 4: 1.7304778099060059\n","epoch time 5.789922714233398\n","Beginning training epoch 238\n","    loss at batch 0: 2.078047275543213\n","    loss at batch 1: 2.6237118244171143\n","    loss at batch 2: 3.176931381225586\n","    loss at batch 3: 3.3031091690063477\n","    loss at batch 4: 2.8173024654388428\n","epoch time 5.746929407119751\n","Beginning training epoch 239\n","    loss at batch 0: 2.1713016033172607\n","    loss at batch 1: 2.171614408493042\n","    loss at batch 2: 2.0679619312286377\n","    loss at batch 3: 2.5552873611450195\n","    loss at batch 4: 1.7565752267837524\n","epoch time 5.812928199768066\n","Beginning training epoch 240\n","    loss at batch 0: 2.360513210296631\n","    loss at batch 1: 1.97652006149292\n","    loss at batch 2: 2.698488235473633\n","    loss at batch 3: 2.7684450149536133\n","    loss at batch 4: 3.616802453994751\n","epoch time 5.768250226974487\n","\n","    Validation loss at epoch 240: 2.4753189086914062\n","\n","Beginning training epoch 241\n","    loss at batch 0: 2.3163700103759766\n","    loss at batch 1: 2.339639902114868\n","    loss at batch 2: 2.3791003227233887\n","    loss at batch 3: 1.9150357246398926\n","    loss at batch 4: 5.045411586761475\n","epoch time 5.910175323486328\n","Beginning training epoch 242\n","    loss at batch 0: 1.816208839416504\n","    loss at batch 1: 2.6306822299957275\n","    loss at batch 2: 2.115779399871826\n","    loss at batch 3: 2.928276538848877\n","    loss at batch 4: 1.834376573562622\n","epoch time 5.752807140350342\n","Beginning training epoch 243\n","    loss at batch 0: 2.634826183319092\n","    loss at batch 1: 1.8775312900543213\n","    loss at batch 2: 2.4898109436035156\n","    loss at batch 3: 2.525949001312256\n","    loss at batch 4: 2.7973244190216064\n","epoch time 5.776197671890259\n","Beginning training epoch 244\n","    loss at batch 0: 2.0974457263946533\n","    loss at batch 1: 2.739596366882324\n","    loss at batch 2: 2.886044979095459\n","    loss at batch 3: 2.2528223991394043\n","    loss at batch 4: 2.410806655883789\n","epoch time 5.801902532577515\n","Beginning training epoch 245\n","    loss at batch 0: 3.0482842922210693\n","    loss at batch 1: 2.938326835632324\n","    loss at batch 2: 2.3506648540496826\n","    loss at batch 3: 2.065011739730835\n","    loss at batch 4: 2.7244114875793457\n","epoch time 5.809818267822266\n","\n","    Validation loss at epoch 245: 2.502810001373291\n","\n","Beginning training epoch 246\n","    loss at batch 0: 2.230635166168213\n","    loss at batch 1: 1.8534486293792725\n","    loss at batch 2: 2.0743935108184814\n","    loss at batch 3: 2.645986557006836\n","    loss at batch 4: 4.383613109588623\n","epoch time 5.865855693817139\n","Beginning training epoch 247\n","    loss at batch 0: 2.816901445388794\n","    loss at batch 1: 2.021913528442383\n","    loss at batch 2: 2.7706193923950195\n","    loss at batch 3: 2.735548257827759\n","    loss at batch 4: 2.4372453689575195\n","epoch time 5.8239076137542725\n","Beginning training epoch 248\n","    loss at batch 0: 1.8843345642089844\n","    loss at batch 1: 2.429191827774048\n","    loss at batch 2: 2.6365745067596436\n","    loss at batch 3: 3.4001593589782715\n","    loss at batch 4: 5.411917686462402\n","epoch time 5.810107946395874\n","Beginning training epoch 249\n","    loss at batch 0: 1.9384782314300537\n","    loss at batch 1: 2.0264458656311035\n","    loss at batch 2: 2.671200752258301\n","    loss at batch 3: 2.89688777923584\n","    loss at batch 4: 1.9295315742492676\n","epoch time 5.7488157749176025\n","Beginning training epoch 250\n","    loss at batch 0: 2.8839271068573\n","    loss at batch 1: 2.559849739074707\n","    loss at batch 2: 2.6650774478912354\n","    loss at batch 3: 1.8931310176849365\n","    loss at batch 4: 2.848604202270508\n","epoch time 5.755813121795654\n","\n","    Validation loss at epoch 250: 2.936513662338257\n","\n","Beginning training epoch 251\n","    loss at batch 0: 2.581360101699829\n","    loss at batch 1: 2.160531759262085\n","    loss at batch 2: 2.58550763130188\n","    loss at batch 3: 2.957737922668457\n","    loss at batch 4: 1.8495821952819824\n","epoch time 5.757650375366211\n","Beginning training epoch 252\n","    loss at batch 0: 2.0061120986938477\n","    loss at batch 1: 2.8426904678344727\n","    loss at batch 2: 3.002570390701294\n","    loss at batch 3: 2.4640278816223145\n","    loss at batch 4: 2.663865566253662\n","epoch time 5.802404403686523\n","Beginning training epoch 253\n","    loss at batch 0: 2.6408140659332275\n","    loss at batch 1: 2.4487862586975098\n","    loss at batch 2: 2.563201427459717\n","    loss at batch 3: 2.9351813793182373\n","    loss at batch 4: 2.7337355613708496\n","epoch time 5.838154554367065\n","Beginning training epoch 254\n","    loss at batch 0: 2.130366086959839\n","    loss at batch 1: 1.9665509462356567\n","    loss at batch 2: 2.320904493331909\n","    loss at batch 3: 3.2612593173980713\n","    loss at batch 4: 9.97585678100586\n","epoch time 5.736971855163574\n","Beginning training epoch 255\n","    loss at batch 0: 2.7012648582458496\n","    loss at batch 1: 1.9632213115692139\n","    loss at batch 2: 2.0449986457824707\n","    loss at batch 3: 3.6763460636138916\n","    loss at batch 4: 2.3383591175079346\n","epoch time 5.8123884201049805\n","\n","    Validation loss at epoch 255: 4.511960029602051\n","\n","Beginning training epoch 256\n","    loss at batch 0: 2.5344135761260986\n","    loss at batch 1: 4.208009243011475\n","    loss at batch 2: 2.327167272567749\n","    loss at batch 3: 3.1804540157318115\n","    loss at batch 4: 3.449134111404419\n","epoch time 5.773339748382568\n","Beginning training epoch 257\n","    loss at batch 0: 2.402963638305664\n","    loss at batch 1: 3.1928839683532715\n","    loss at batch 2: 2.4763693809509277\n","    loss at batch 3: 3.0136470794677734\n","    loss at batch 4: 1.7681360244750977\n","epoch time 5.721710205078125\n","Beginning training epoch 258\n","    loss at batch 0: 2.554046630859375\n","    loss at batch 1: 2.286931037902832\n","    loss at batch 2: 2.6454977989196777\n","    loss at batch 3: 2.61568284034729\n","    loss at batch 4: 4.0213303565979\n","epoch time 5.89860987663269\n","Beginning training epoch 259\n","    loss at batch 0: 2.4407012462615967\n","    loss at batch 1: 2.719137191772461\n","    loss at batch 2: 2.471665143966675\n","    loss at batch 3: 2.8945670127868652\n","    loss at batch 4: 2.452770948410034\n","epoch time 5.837210655212402\n","Beginning training epoch 260\n","    loss at batch 0: 2.770613670349121\n","    loss at batch 1: 2.382626533508301\n","    loss at batch 2: 4.038495063781738\n","    loss at batch 3: 2.2124288082122803\n","    loss at batch 4: 2.2186617851257324\n","epoch time 5.874328374862671\n","\n","    Validation loss at epoch 260: 3.1017632484436035\n","\n","Beginning training epoch 261\n","    loss at batch 0: 2.5864946842193604\n","    loss at batch 1: 2.251746654510498\n","    loss at batch 2: 2.8613762855529785\n","    loss at batch 3: 1.91379714012146\n","    loss at batch 4: 3.5017242431640625\n","epoch time 5.775777816772461\n","Beginning training epoch 262\n","    loss at batch 0: 2.876258611679077\n","    loss at batch 1: 2.0010268688201904\n","    loss at batch 2: 1.8700523376464844\n","    loss at batch 3: 2.4880523681640625\n","    loss at batch 4: 3.1409828662872314\n","epoch time 5.888948917388916\n","Beginning training epoch 263\n","    loss at batch 0: 1.9776737689971924\n","    loss at batch 1: 2.7578787803649902\n","    loss at batch 2: 2.346118927001953\n","    loss at batch 3: 2.7572877407073975\n","    loss at batch 4: 1.7669657468795776\n","epoch time 5.80420994758606\n","Beginning training epoch 264\n","    loss at batch 0: 2.7456626892089844\n","    loss at batch 1: 2.7907986640930176\n","    loss at batch 2: 2.6703877449035645\n","    loss at batch 3: 2.267763137817383\n","    loss at batch 4: 2.000981330871582\n","epoch time 6.522641658782959\n","Beginning training epoch 265\n","    loss at batch 0: 2.2609665393829346\n","    loss at batch 1: 3.5068869590759277\n","    loss at batch 2: 2.2369301319122314\n","    loss at batch 3: 1.553644061088562\n","    loss at batch 4: 2.3518638610839844\n","epoch time 6.578165769577026\n","\n","    Validation loss at epoch 265: 2.996938467025757\n","\n","Beginning training epoch 266\n","    loss at batch 0: 2.3272576332092285\n","    loss at batch 1: 1.908897876739502\n","    loss at batch 2: 3.0556445121765137\n","    loss at batch 3: 3.335296392440796\n","    loss at batch 4: 2.332244873046875\n","epoch time 6.510121583938599\n","Beginning training epoch 267\n","    loss at batch 0: 2.1210150718688965\n","    loss at batch 1: 2.0369925498962402\n","    loss at batch 2: 2.26350474357605\n","    loss at batch 3: 2.381302833557129\n","    loss at batch 4: 1.7659997940063477\n","epoch time 6.623866558074951\n","Beginning training epoch 268\n","    loss at batch 0: 2.497520685195923\n","    loss at batch 1: 1.9256980419158936\n","    loss at batch 2: 2.2310914993286133\n","    loss at batch 3: 2.1748180389404297\n","    loss at batch 4: 1.4162296056747437\n","epoch time 6.449841022491455\n","Beginning training epoch 269\n","    loss at batch 0: 2.118791341781616\n","    loss at batch 1: 2.310027599334717\n","    loss at batch 2: 2.503077268600464\n","    loss at batch 3: 1.6755797863006592\n","    loss at batch 4: 2.0473480224609375\n","epoch time 6.561793088912964\n","Beginning training epoch 270\n","    loss at batch 0: 1.9366050958633423\n","    loss at batch 1: 2.073756694793701\n","    loss at batch 2: 1.5754907131195068\n","    loss at batch 3: 1.9297428131103516\n","    loss at batch 4: 3.151186466217041\n","epoch time 5.86605978012085\n","\n","    Validation loss at epoch 270: 2.601663827896118\n","\n","Beginning training epoch 271\n","    loss at batch 0: 3.216712474822998\n","    loss at batch 1: 2.1673269271850586\n","    loss at batch 2: 2.458211660385132\n","    loss at batch 3: 1.8383480310440063\n","    loss at batch 4: 2.3960628509521484\n","epoch time 5.919195652008057\n","Beginning training epoch 272\n","    loss at batch 0: 2.131403923034668\n","    loss at batch 1: 2.746696949005127\n","    loss at batch 2: 2.493023157119751\n","    loss at batch 3: 1.8988038301467896\n","    loss at batch 4: 1.9426900148391724\n","epoch time 6.380579471588135\n","Beginning training epoch 273\n","    loss at batch 0: 1.8466740846633911\n","    loss at batch 1: 2.9757797718048096\n","    loss at batch 2: 2.0904409885406494\n","    loss at batch 3: 2.918189764022827\n","    loss at batch 4: 2.417325258255005\n","epoch time 5.848290205001831\n","Beginning training epoch 274\n","    loss at batch 0: 1.7338553667068481\n","    loss at batch 1: 1.916062355041504\n","    loss at batch 2: 2.480074644088745\n","    loss at batch 3: 2.3476200103759766\n","    loss at batch 4: 1.981520652770996\n","epoch time 5.792622804641724\n","Beginning training epoch 275\n","    loss at batch 0: 1.8261809349060059\n","    loss at batch 1: 2.2267322540283203\n","    loss at batch 2: 2.1561858654022217\n","    loss at batch 3: 2.1660354137420654\n","    loss at batch 4: 1.2441383600234985\n","epoch time 5.813167095184326\n","\n","    Validation loss at epoch 275: 2.274562358856201\n","\n","Beginning training epoch 276\n","    loss at batch 0: 2.5312047004699707\n","    loss at batch 1: 3.058690071105957\n","    loss at batch 2: 1.7217234373092651\n","    loss at batch 3: 1.983141541481018\n","    loss at batch 4: 2.054386615753174\n","epoch time 5.814829587936401\n","Beginning training epoch 277\n","    loss at batch 0: 2.007384777069092\n","    loss at batch 1: 2.55368709564209\n","    loss at batch 2: 2.1417908668518066\n","    loss at batch 3: 1.929848551750183\n","    loss at batch 4: 3.5694785118103027\n","epoch time 5.854326963424683\n","Beginning training epoch 278\n","    loss at batch 0: 2.286404609680176\n","    loss at batch 1: 2.5295872688293457\n","    loss at batch 2: 1.9611971378326416\n","    loss at batch 3: 2.7060203552246094\n","    loss at batch 4: 1.5678062438964844\n","epoch time 5.832716226577759\n","Beginning training epoch 279\n","    loss at batch 0: 2.274662971496582\n","    loss at batch 1: 2.8652212619781494\n","    loss at batch 2: 2.6650333404541016\n","    loss at batch 3: 2.5746703147888184\n","    loss at batch 4: 2.785841464996338\n","epoch time 5.749309301376343\n","Beginning training epoch 280\n","    loss at batch 0: 2.7984485626220703\n","    loss at batch 1: 2.1922824382781982\n","    loss at batch 2: 2.2341723442077637\n","    loss at batch 3: 3.268566846847534\n","    loss at batch 4: 2.263481616973877\n","epoch time 5.80201530456543\n","\n","    Validation loss at epoch 280: 2.166407585144043\n","\n","Beginning training epoch 281\n","    loss at batch 0: 1.9795351028442383\n","    loss at batch 1: 2.357227087020874\n","    loss at batch 2: 2.2057740688323975\n","    loss at batch 3: 2.399766683578491\n","    loss at batch 4: 2.522554636001587\n","epoch time 5.856242656707764\n","Beginning training epoch 282\n","    loss at batch 0: 2.3087663650512695\n","    loss at batch 1: 2.519500970840454\n","    loss at batch 2: 2.160745143890381\n","    loss at batch 3: 3.1174373626708984\n","    loss at batch 4: 2.724858522415161\n","epoch time 5.867867946624756\n","Beginning training epoch 283\n","    loss at batch 0: 2.283450126647949\n","    loss at batch 1: 1.955540418624878\n","    loss at batch 2: 2.21174955368042\n","    loss at batch 3: 3.117615222930908\n","    loss at batch 4: 1.5422614812850952\n","epoch time 5.801003456115723\n","Beginning training epoch 284\n","    loss at batch 0: 2.265547752380371\n","    loss at batch 1: 2.4923031330108643\n","    loss at batch 2: 2.325417995452881\n","    loss at batch 3: 2.2726235389709473\n","    loss at batch 4: 2.0222246646881104\n","epoch time 5.910242319107056\n","Beginning training epoch 285\n","    loss at batch 0: 2.676208257675171\n","    loss at batch 1: 1.6552180051803589\n","    loss at batch 2: 2.5277395248413086\n","    loss at batch 3: 1.978675365447998\n","    loss at batch 4: 1.2428923845291138\n","epoch time 5.995145320892334\n","\n","    Validation loss at epoch 285: 2.4578676223754883\n","\n","Beginning training epoch 286\n","    loss at batch 0: 2.341592788696289\n","    loss at batch 1: 2.151024580001831\n","    loss at batch 2: 2.0880730152130127\n","    loss at batch 3: 2.0417726039886475\n","    loss at batch 4: 1.4383246898651123\n","epoch time 5.8483726978302\n","Beginning training epoch 287\n","    loss at batch 0: 2.0399329662323\n","    loss at batch 1: 2.0711724758148193\n","    loss at batch 2: 2.0014023780822754\n","    loss at batch 3: 1.9287362098693848\n","    loss at batch 4: 2.8213348388671875\n","epoch time 5.789213418960571\n","Beginning training epoch 288\n","    loss at batch 0: 2.2262463569641113\n","    loss at batch 1: 2.168020486831665\n","    loss at batch 2: 2.052382469177246\n","    loss at batch 3: 2.264875888824463\n","    loss at batch 4: 1.9759286642074585\n","epoch time 5.660836935043335\n","Beginning training epoch 289\n","    loss at batch 0: 2.096614360809326\n","    loss at batch 1: 1.8851083517074585\n","    loss at batch 2: 2.120138645172119\n","    loss at batch 3: 2.972590923309326\n","    loss at batch 4: 3.151089668273926\n","epoch time 5.797446250915527\n","Beginning training epoch 290\n","    loss at batch 0: 1.7580499649047852\n","    loss at batch 1: 2.119861125946045\n","    loss at batch 2: 2.567539930343628\n","    loss at batch 3: 1.7886358499526978\n","    loss at batch 4: 2.4612410068511963\n","epoch time 5.8048741817474365\n","\n","    Validation loss at epoch 290: 2.083831310272217\n","\n","Beginning training epoch 291\n","    loss at batch 0: 1.955306887626648\n","    loss at batch 1: 2.80582857131958\n","    loss at batch 2: 2.682863712310791\n","    loss at batch 3: 1.7335337400436401\n","    loss at batch 4: 1.3933130502700806\n","epoch time 6.465310096740723\n","Beginning training epoch 292\n","    loss at batch 0: 2.076711893081665\n","    loss at batch 1: 1.9301331043243408\n","    loss at batch 2: 2.9638447761535645\n","    loss at batch 3: 2.1911938190460205\n","    loss at batch 4: 2.1352880001068115\n","epoch time 6.419168949127197\n","Beginning training epoch 293\n","    loss at batch 0: 2.3056511878967285\n","    loss at batch 1: 2.0958659648895264\n","    loss at batch 2: 2.0526509284973145\n","    loss at batch 3: 1.904701590538025\n","    loss at batch 4: 2.241420030593872\n","epoch time 6.288857698440552\n","Beginning training epoch 294\n","    loss at batch 0: 2.5461370944976807\n","    loss at batch 1: 2.259446859359741\n","    loss at batch 2: 2.483067274093628\n","    loss at batch 3: 1.7464607954025269\n","    loss at batch 4: 2.1836931705474854\n","epoch time 6.420602798461914\n","Beginning training epoch 295\n","    loss at batch 0: 2.0239529609680176\n","    loss at batch 1: 2.196234703063965\n","    loss at batch 2: 2.587618350982666\n","    loss at batch 3: 2.6689581871032715\n","    loss at batch 4: 1.335115671157837\n","epoch time 5.933356761932373\n","\n","    Validation loss at epoch 295: 2.531085968017578\n","\n","Beginning training epoch 296\n","    loss at batch 0: 1.8921139240264893\n","    loss at batch 1: 2.3373255729675293\n","    loss at batch 2: 2.3625643253326416\n","    loss at batch 3: 2.0983476638793945\n","    loss at batch 4: 1.8177205324172974\n","epoch time 5.855895042419434\n","Beginning training epoch 297\n","    loss at batch 0: 2.0630757808685303\n","    loss at batch 1: 2.1996724605560303\n","    loss at batch 2: 1.9482227563858032\n","    loss at batch 3: 2.1136298179626465\n","    loss at batch 4: 4.412371635437012\n","epoch time 5.730095863342285\n","Beginning training epoch 298\n","    loss at batch 0: 2.5832061767578125\n","    loss at batch 1: 2.186828851699829\n","    loss at batch 2: 2.094170331954956\n","    loss at batch 3: 2.4541139602661133\n","    loss at batch 4: 2.5010719299316406\n","epoch time 5.780561923980713\n","Beginning training epoch 299\n","    loss at batch 0: 2.2741262912750244\n","    loss at batch 1: 2.7846081256866455\n","    loss at batch 2: 2.5357062816619873\n","    loss at batch 3: 2.5484797954559326\n","    loss at batch 4: 1.588128924369812\n","epoch time 5.712630748748779\n"]}],"source":["import multiprocessing\n","#import pandas as pd\n","import numpy as np\n","import skimage\n","#import gdal\n","import sys\n","import os\n","# sys.path.insert(0, '/content/DMNet_Rina/training_codes/solaris_rina')\n","# print (sys.path)\n","os.chdir(\"/content/DMNet_Rina/training_codes/\")\n","sol = __import__('solaris_rina')\n","\n","\n","# Dataset location (edit as needed)\n","dataset_namein = \"DIC-C2DH-HeLa\"\n","gttype=\"GT\"\n","branch=\"mask\"\n","config_path=\"/content/DMNet_Rina/training_codes/yml/all_eachcell.yml\"\n","# Load config\n","config = sol.utils.config.parse(config_path)\n","\n","\n","# %% ============================\n","# Training\n","# ===============================\n","\n","# make model output dir\n","\n","\n","\n","os.makedirs(os.path.dirname(config['training']['model_dest_path']), exist_ok=True)\n","config['pretrained_rina']=True\n","#if gttype in [\"GT\"]:\n","#    config['training']['epochs']=100\n","#from sol.nets import datagen_cell\n","trainer = sol.nets.train_cell_GTST.Trainer(config=config,dataset_name=dataset_namein,branch=branch,GT=gttype)\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"qz0JKlLUnIrl"},"source":["# Create a requirements file to install all the dependencies for colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-oSFPAZuSx8"},"outputs":[],"source":["import ipykernel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"elapsed":282,"status":"error","timestamp":1642367636607,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04592796515262324641"},"user_tz":0},"id":"CydMsk1Atkwx","outputId":"aa486c09-1693-4ac6-fbd8-da72c46bddb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["BF-C2DL-HSC/01_RES-GT\n","check center path ../wdata/ctc/BF-C2DL-HSC/shapemarker/GT\n","loading model ../wdata/ctc/BF-C2DL-HSC/mask/GT/hrnet_final.pth ../wdata/ctc/BF-C2DL-HSC/shapemarker/GT/hrnet_final.pth\n"]},{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-e802fee36432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0min_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-e802fee36432>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdet_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mget_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_imgpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgttype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#get_noor_track_results(inp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m################ generating tracking ##################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DMNet_Rina/inference_codes/testSet/generate_Detections_78.py\u001b[0m in \u001b[0;36mget_detection\u001b[0;34m(input_imgpath, save_rina_seg_path, da, gttype, model_choose, vis, all)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"loading model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcentermarker_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mcenter_inferer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInferer_singleimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentermarker_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mmask_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInferer_singleimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DMNet_Rina/inference_codes/testSet/Inference_dataset_newmodel_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         self.transforms = transforms.Compose([\n","\u001b[0;32m/content/DMNet_Rina/inference_codes/testSet/model_io.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHighResolutionNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# if it's a full model already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../wdata/ctc/BF-C2DL-HSC/shapemarker/GT/hrnet_final.pth'"]}],"source":["import sys\n","sys.path.append(\"./testSet/\")\n","import os \n","os.chdir(\"/content/DMNet_Rina/inference_codes/testSet\")\n","from generate_Detections_78 import get_detection\n","#from track_bbox import get_noor_track_results as get_noor_track_results_bbox\n","#from track_mask import get_noor_track_results as get_noor_track_results_mask\n","\n","import os\n","import os.path as osp\n","from post_processing_shape import roi_correct\n","BF_list=[\"BF-C2DL-HSC\",\n","            \"BF-C2DL-MuSC\"]\n","def main(inp):\n","\n","    da=\"BF-C2DL-HSC\"\n","    se=\"01\"\n","    out_path=\"BF-C2DL-HSC/01_RES-GT\"\n","\n","    da_name=\"BF-C2DL-HSC\"\n","    gttype=\"GT\"\n","    all=int(0)\n","    ################ generating detection #################\n","    input_imgpath=osp.join(da,se)\n","    det_path=out_path\n","    os.makedirs(det_path, exist_ok=True)\n","    print (det_path)\n","    get_detection(input_imgpath, det_path, da_name,gttype,vis=0,all=all)\n","    #get_noor_track_results(inp)\n","    ################ generating tracking ##################\n","    #if da in ['BF-C2DL-MuSC', 'Fluo-C2DL-MSC']:\n","    #    get_noor_track_results_mask(det_path,da,se,out_path)\n","    #else:\n","    #    get_noor_track_results_bbox(det_path,da,se,out_path)\n","\n","    if da_name in BF_list:\n","        roi_correct(det_path, det_path)\n","\n","if __name__ == '__main__':\n","    in_p=sys.argv\n","    main(in_p)\n"]},{"cell_type":"markdown","metadata":{"id":"IO_tAgjwSBQd"},"source":["# Notes for MU-Ra-US = ctc681 SW\n","\n","- Provide a requirements file with the correct list of dependencies:\n","\n","> !pip uninstall imgaug\n","\n","> !pip install git+https://github.com/aleju/imgaug.git\n","\n","- I need to install imagecodecs to process the images of the CTC, but this can vary according to the data we want to use. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3gr81P8vmvwi"},"outputs":[],"source":["!pip install ruamel.yaml\n","import os\n","os.chdir(\"/content/DMNet_Rina/training_codes\")\n","import ruamel.yaml\n","\n","yaml = ruamel.yaml.YAML()\n","data = yaml.load(open('environment.yml'))\n","\n","requirements = []\n","for dep in data['dependencies']:\n","    if isinstance(dep, str):\n","        package, package_version, python_version = dep.split('=')\n","        if python_version == '0':\n","            continue\n","        requirements.append(package + '==' + package_version)\n","    elif isinstance(dep, dict):\n","        for preq in dep.get('pip', []):\n","            requirements.append(preq)\n","\n","with open('requirements.txt', 'w') as fp:\n","    for requirement in requirements:\n","       print(requirement, file=fp)\n","!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2B0wMZbJ2tv"},"outputs":[],"source":["# Install the dependencies (I created a requirements file from environment.yaml to be compatible with colab)\n","os.chdir(\"/content/drive/MyDrive/Estibaliz Gomez de Mariscal/CELL TRACKING CHALLENGE (CTC)/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682\")\n","!ls\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"Wy3LlGtLey_T"},"source":["# Training with DIC-C2DH-HeLa dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28217,"status":"ok","timestamp":1640171927792,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04592796515262324641"},"user_tz":0},"id":"hZvEn1dNcIGE","outputId":"e30a1bf5-2a8a-48ab-c3f5-575cf38de610"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: imgaug 0.2.9\n","Uninstalling imgaug-0.2.9:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/imgaug-0.2.9.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/imgaug/*\n","Proceed (y/n)? y\n","  Successfully uninstalled imgaug-0.2.9\n","Collecting git+https://github.com/aleju/imgaug.git\n","  Cloning https://github.com/aleju/imgaug.git to /tmp/pip-req-build-c7oomgxx\n","  Running command git clone -q https://github.com/aleju/imgaug.git /tmp/pip-req-build-c7oomgxx\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.15.0)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.4.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (3.2.2)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (0.18.3)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (4.1.2.30)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.8.0)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (2.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2.6.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (3.0.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (0.11.0)\n","Building wheels for collected packages: imgaug\n","  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imgaug: filename=imgaug-0.4.0-py3-none-any.whl size=971122 sha256=c26b37ccb8823d50199846d4015a4cbdfe2a834f3a67d95a7da8a93d7861df1f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-f0w_ghv9/wheels/0c/78/b5/9303fae9d5e03df1f319adfe4e6534180b5c3232de11bc9a2f\n","Successfully built imgaug\n","Installing collected packages: imgaug\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.4.0 which is incompatible.\u001b[0m\n","Successfully installed imgaug-0.4.0\n"]}],"source":["!pip uninstall imgaug\n","!pip install git+https://github.com/aleju/imgaug.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49059,"status":"ok","timestamp":1640172118676,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04592796515262324641"},"user_tz":0},"id":"b5Bxlzgulpv6","outputId":"41190332-3a06-48a8-e653-68e1b0dc660b"},"outputs":[{"name":"stdout","output_type":"stream","text":["['solaris_rina', '/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes', '/tensorflow-1.15.2/python3.7', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages']\n","/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_GT.json\n","Traceback (most recent call last):\n","  File \"../train_unify.py\", line 34, in <module>\n","    trainer = sol.nets.train_cell_GTST.Trainer(config=config,dataset_name=dataset_namein,branch=branch,GT=gttype)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 53, in __init__\n","    self.train_df, self.val_df = get_train_val_dfs(self.config,dataset_name,GT)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 309, in get_train_val_dfs\n","    with open(pathload) as f:\n","FileNotFoundError: [Errno 2] No such file or directory: '/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_GT.json'\n","['solaris_rina', '/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes', '/tensorflow-1.15.2/python3.7', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages']\n","/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_GT.json\n","Traceback (most recent call last):\n","  File \"../train_unify.py\", line 34, in <module>\n","    trainer = sol.nets.train_cell_GTST.Trainer(config=config,dataset_name=dataset_namein,branch=branch,GT=gttype)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 53, in __init__\n","    self.train_df, self.val_df = get_train_val_dfs(self.config,dataset_name,GT)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 309, in get_train_val_dfs\n","    with open(pathload) as f:\n","FileNotFoundError: [Errno 2] No such file or directory: '/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_GT.json'\n","['solaris_rina', '/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes', '/tensorflow-1.15.2/python3.7', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages']\n","/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_GT+ST.json\n","Traceback (most recent call last):\n","  File \"../train_unify.py\", line 34, in <module>\n","    trainer = sol.nets.train_cell_GTST.Trainer(config=config,dataset_name=dataset_namein,branch=branch,GT=gttype)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 53, in __init__\n","    self.train_df, self.val_df = get_train_val_dfs(self.config,dataset_name,GT)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 309, in get_train_val_dfs\n","    with open(pathload) as f:\n","FileNotFoundError: [Errno 2] No such file or directory: '/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_GT+ST.json'\n","['solaris_rina', '/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes', '/tensorflow-1.15.2/python3.7', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages']\n","/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_GT+ST.json\n","Traceback (most recent call last):\n","  File \"../train_unify.py\", line 34, in <module>\n","    trainer = sol.nets.train_cell_GTST.Trainer(config=config,dataset_name=dataset_namein,branch=branch,GT=gttype)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 53, in __init__\n","    self.train_df, self.val_df = get_train_val_dfs(self.config,dataset_name,GT)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 309, in get_train_val_dfs\n","    with open(pathload) as f:\n","FileNotFoundError: [Errno 2] No such file or directory: '/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_GT+ST.json'\n","['solaris_rina', '/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes', '/tensorflow-1.15.2/python3.7', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages']\n","/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_ST.json\n","Traceback (most recent call last):\n","  File \"../train_unify.py\", line 34, in <module>\n","    trainer = sol.nets.train_cell_GTST.Trainer(config=config,dataset_name=dataset_namein,branch=branch,GT=gttype)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 53, in __init__\n","    self.train_df, self.val_df = get_train_val_dfs(self.config,dataset_name,GT)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 309, in get_train_val_dfs\n","    with open(pathload) as f:\n","FileNotFoundError: [Errno 2] No such file or directory: '/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_ST.json'\n","['solaris_rina', '/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes', '/tensorflow-1.15.2/python3.7', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages']\n","/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_ST.json\n","Traceback (most recent call last):\n","  File \"../train_unify.py\", line 34, in <module>\n","    trainer = sol.nets.train_cell_GTST.Trainer(config=config,dataset_name=dataset_namein,branch=branch,GT=gttype)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 53, in __init__\n","    self.train_df, self.val_df = get_train_val_dfs(self.config,dataset_name,GT)\n","  File \"/content/drive/.shortcut-targets-by-id/1OlSNYgJrq3rUCdAT1yjr67QZ4rloM0pm/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/solaris_rina/nets/train_cell_GTST.py\", line 309, in get_train_val_dfs\n","    with open(pathload) as f:\n","FileNotFoundError: [Errno 2] No such file or directory: '/home/rbync/data/top1splits/splits/ids_DIC-C2DH-HeLa_ST.json'\n"]}],"source":["## Download the training data from the CTC in the Data/train folder of the software\n","os.chdir(\"/content/drive/MyDrive/Estibaliz Gomez de Mariscal/CELL TRACKING CHALLENGE (CTC)/CTC trainable solutions/Data Estibaliz/Mu-Ba-US = ctc682/SW/DMNet/Codes/generate_bash\")\n","!bash DIC-C2DH-HeLa.sh\n","# !bash allGT.sh\n","# !bash allST.sh\n","# !bash allGT+ST.sh\n","\n","\n","# !wget --no-check-certificate http://data.celltrackingchallenge.net/training-datasets/DIC-C2DH-HeLa.zip\n","# !unzip DIC-C2DH-HeLa.zip\n","# !rm -r DIC-C2DH-HeLa.zip"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CheckNotebook_Mu-Ba-US.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
